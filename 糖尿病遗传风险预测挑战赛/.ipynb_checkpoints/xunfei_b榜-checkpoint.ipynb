{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "train_df=pd.read_csv('比赛训练集.csv',encoding='gbk')\n",
    "test_df=pd.read_csv('b榜新数据集.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(np.arange(1,4001))\n",
    "result['label'] = 0\n",
    "result.rename(columns={0:\"uuid\"}).to_csv('提交示例.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#result = pd.read_csv('提交示例.csv')\n",
    "#result=result.append(pd.DataFrame(np.arange(1001,4001)),ignore_index = True)\n",
    "#result = result.drop([0],axis=1)\n",
    "#result['uuid'] = pd.DataFrame(np.arange(1,4001))\n",
    "#result.to_csv('提交示例.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 探索性数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的数据大小： (5070, 10)\n",
      "测试集的数据大小： (4000, 9)\n",
      "------------------------------\n",
      "训练集的数据类型：\n",
      "编号            int64\n",
      "性别            int64\n",
      "出生年份          int64\n",
      "体重指数        float64\n",
      "糖尿病家族史       object\n",
      "舒张压         float64\n",
      "口服耐糖量测试     float64\n",
      "胰岛素释放实验     float64\n",
      "肱三头肌皮褶厚度    float64\n",
      "患有糖尿病标识       int64\n",
      "dtype: object\n",
      "------------------------------\n",
      "编号            int64\n",
      "性别            int64\n",
      "出生年份          int64\n",
      "体重指数        float64\n",
      "糖尿病家族史       object\n",
      "舒张压           int64\n",
      "口服耐糖量测试     float64\n",
      "胰岛素释放实验     float64\n",
      "肱三头肌皮褶厚度    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('训练集的数据大小：',train_df.shape)\n",
    "print('测试集的数据大小：',test_df.shape)\n",
    "print('-'*30)\n",
    "print('训练集的数据类型：')\n",
    "print(train_df.dtypes)\n",
    "print('-'*30)\n",
    "print(test_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编号            0\n",
      "性别            0\n",
      "出生年份          0\n",
      "体重指数          0\n",
      "糖尿病家族史        0\n",
      "舒张压         247\n",
      "口服耐糖量测试       0\n",
      "胰岛素释放实验       0\n",
      "肱三头肌皮褶厚度      0\n",
      "患有糖尿病标识       0\n",
      "dtype: int64\n",
      "------------------------------\n",
      "编号          0\n",
      "性别          0\n",
      "出生年份        0\n",
      "体重指数        0\n",
      "糖尿病家族史      0\n",
      "舒张压         0\n",
      "口服耐糖量测试     0\n",
      "胰岛素释放实验     0\n",
      "肱三头肌皮褶厚度    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#----------------查数据的缺失值----------------\n",
    "print(train_df.isnull().sum())\n",
    "print('-'*30)\n",
    "print(test_df.isnull().sum())\n",
    "#可以看到 训练集和测试集中都是舒张压有缺失值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "查看训练集中数据的相关性\n",
      "                编号        性别      出生年份      体重指数       舒张压   口服耐糖量测试  \\\n",
      "编号        1.000000  0.006603 -0.006693  0.000028  0.003495 -0.005840   \n",
      "性别        0.006603  1.000000 -0.119563  0.075186  0.078870  0.011463   \n",
      "出生年份     -0.006693 -0.119563  1.000000 -0.074603 -0.154631  0.002085   \n",
      "体重指数      0.000028  0.075186 -0.074603  1.000000  0.159903 -0.001796   \n",
      "舒张压       0.003495  0.078870 -0.154631  0.159903  1.000000 -0.020317   \n",
      "口服耐糖量测试  -0.005840  0.011463  0.002085 -0.001796 -0.020317  1.000000   \n",
      "胰岛素释放实验   0.020441 -0.053597  0.058585 -0.034507 -0.206663  0.093715   \n",
      "肱三头肌皮褶厚度  0.030330  0.014037 -0.013111  0.026321  0.076147 -0.006483   \n",
      "患有糖尿病标识   0.027435  0.031480 -0.068225  0.377919  0.157421  0.178133   \n",
      "\n",
      "           胰岛素释放实验  肱三头肌皮褶厚度   患有糖尿病标识  \n",
      "编号        0.020441  0.030330  0.027435  \n",
      "性别       -0.053597  0.014037  0.031480  \n",
      "出生年份      0.058585 -0.013111 -0.068225  \n",
      "体重指数     -0.034507  0.026321  0.377919  \n",
      "舒张压      -0.206663  0.076147  0.157421  \n",
      "口服耐糖量测试   0.093715 -0.006483  0.178133  \n",
      "胰岛素释放实验   1.000000 -0.015479  0.156656  \n",
      "肱三头肌皮褶厚度 -0.015479  1.000000  0.410667  \n",
      "患有糖尿病标识   0.156656  0.410667  1.000000  \n",
      "                编号        性别      出生年份      体重指数       舒张压   口服耐糖量测试  \\\n",
      "编号        1.000000 -0.006601  0.000027 -0.005516 -0.000289 -0.007800   \n",
      "性别       -0.006601  1.000000 -0.006767  0.024746 -0.001264  0.036579   \n",
      "出生年份      0.000027 -0.006767  1.000000 -0.029279 -0.241039 -0.189673   \n",
      "体重指数     -0.005516  0.024746 -0.029279  1.000000  0.202130  0.206397   \n",
      "舒张压      -0.000289 -0.001264 -0.241039  0.202130  1.000000  0.145952   \n",
      "口服耐糖量测试  -0.007800  0.036579 -0.189673  0.206397  0.145952  1.000000   \n",
      "胰岛素释放实验   0.001115  0.008120  0.025102  0.182875  0.063118  0.264430   \n",
      "肱三头肌皮褶厚度 -0.002828 -0.002831  0.035250  0.361920  0.122252  0.095007   \n",
      "\n",
      "           胰岛素释放实验  肱三头肌皮褶厚度  \n",
      "编号        0.001115 -0.002828  \n",
      "性别        0.008120 -0.002831  \n",
      "出生年份      0.025102  0.035250  \n",
      "体重指数      0.182875  0.361920  \n",
      "舒张压       0.063118  0.122252  \n",
      "口服耐糖量测试   0.264430  0.095007  \n",
      "胰岛素释放实验   1.000000  0.317031  \n",
      "肱三头肌皮褶厚度  0.317031  1.000000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#----------------查数据相关性----------------\n",
    "print('-'*30)\n",
    "print('查看训练集中数据的相关性')\n",
    "print(train_df.corr())\n",
    "print(test_df.corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#----------------数据的可视化统计----------------\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m性别\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbarh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "#----------------数据的可视化统计----------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train_df['性别'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(font='SimHei',font_scale=1.1)  # 解决Seaborn中文显示问题并调整字体大小\n",
    "sns.countplot(x='患有糖尿病标识', hue='性别', data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(y='出生年份', x='患有糖尿病标识', hue='性别', data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.violinplot(y='体重指数', x='患有糖尿病标识', hue='性别', data=train_df)\n",
    "plt.figure(figsize = [20,10],dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='出生年份',data=train_df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#这里将文本数据转成数字数据\n",
    "dict_糖尿病家族史 = {\n",
    "    '无记录': 0,\n",
    "    '叔叔或姑姑有一方患有糖尿病': 1,\n",
    "    '叔叔或者姑姑有一方患有糖尿病': 1,\n",
    "    '父母有一方患有糖尿病': 2\n",
    "}\n",
    "\n",
    "train_df['糖尿病家族史'] = train_df['糖尿病家族史'].map(dict_糖尿病家族史)\n",
    "test_df['糖尿病家族史'] = test_df['糖尿病家族史'].map(dict_糖尿病家族史)\n",
    "\n",
    "#考虑到舒张压是一个较为重要的生理特征，并不能适用于填充平均值，这里采用填充为0的方法\n",
    "train_df['舒张压'].fillna(0, inplace=True)\n",
    "test_df['舒张压'].fillna(0, inplace=True)\n",
    "\n",
    "#将数据中的出生年份换算成年龄\n",
    "train_df['出生年份'] = 2022 - train_df['出生年份']\n",
    "test_df['出生年份'] = 2022 - test_df['出生年份']\n",
    "\n",
    "#将年龄进行一个分类\n",
    "\"\"\"\n",
    ">50\n",
    "<=18\n",
    "19-30\n",
    "31-50\n",
    "\"\"\"\n",
    "def resetAge(input):\n",
    "    if input<=18:\n",
    "        return 0\n",
    "    elif 19<=input<=30:\n",
    "        return 1\n",
    "    elif 31<=input<=50:\n",
    "        return 2\n",
    "    elif input>=51:\n",
    "        return 3\n",
    "\n",
    "train_df['rAge']=train_df['出生年份'].apply(resetAge)\n",
    "test_df['rAge']=test_df['出生年份'].apply(resetAge)\n",
    "\n",
    "#将体重指数进行一个分类\n",
    "\"\"\"\n",
    "人体的成人体重指数正常值是在18.5-24之间\n",
    "低于18.5是体重指数过轻\n",
    "在24-27之间是体重超重\n",
    "27以上考虑是肥胖\n",
    "高于32了就是非常的肥胖。\n",
    "\"\"\"\n",
    "def BMI(a):\n",
    "    if a<18.5:\n",
    "        return 0\n",
    "    elif 18.5<=a<=24:\n",
    "        return 1\n",
    "    elif 24<a<=27:\n",
    "        return 2\n",
    "    elif 27<a<=32:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "train_df['BMI']=train_df['体重指数'].apply(BMI)\n",
    "test_df['BMI']=test_df['体重指数'].apply(BMI)\n",
    "#将舒张压进行一个分组\n",
    "\"\"\"\n",
    "舒张压范围为60-90\n",
    "\"\"\"\n",
    "def DBP(a):\n",
    "    if a==0:#这里为数据缺失的情况\n",
    "        return 0\n",
    "    elif 0<a<60:\n",
    "        return 1\n",
    "    elif 60<=a<=90:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "train_df['DBP']=train_df['舒张压'].apply(DBP)\n",
    "test_df['DBP']=test_df['舒张压'].apply(DBP)\n",
    "\n",
    "#删除编号\n",
    "train_df=train_df.drop(['编号'],axis=1)\n",
    "test_df=test_df.drop(['编号'],axis=1)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df[train_df[\"舒张压\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#这里计算口服耐糖量相对糖尿病家族史进行分组求平均值后的差值\n",
    "train_df['口服耐糖量测试_diff'] = abs(train_df['口服耐糖量测试'] - train_df.groupby('糖尿病家族史').transform('mean')['口服耐糖量测试'])\n",
    "test_df['口服耐糖量测试_diff'] = abs(test_df['口服耐糖量测试'] - test_df.groupby('糖尿病家族史').transform('mean')['口服耐糖量测试'])\n",
    "\n",
    "#这里计算口服耐糖量相对年龄进行分组求平均值后的差值\n",
    "train_df['口服耐糖量测试_diff'] = abs(train_df['口服耐糖量测试'] - train_df.groupby('rAge').transform('mean')['口服耐糖量测试'])\n",
    "test_df['口服耐糖量测试_diff'] = abs(test_df['口服耐糖量测试'] - test_df.groupby('rAge').transform('mean')['口服耐糖量测试'])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "连续型特征什么时候需要分箱处理，什么时候不需要处理。\n",
    "年龄、体重、舒张压分箱后相当于增加了一个特征，那么有三种情况，分别是不做处理、保留分箱特征、两者都保留。哪种效果会好些呢？怎么判断。\n",
    "空值用随机森林进行填充效果会更好吗？或者其他的方法填充空值。\n",
    "特征选择-过滤法\n",
    "特征构造\n",
    "更多的超参数优化\n",
    "\"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **一级模型对比**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,KFold,cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "#划分训练集和验证集\n",
    "train_label=train_df['患有糖尿病标识']\n",
    "train=train_df.drop(['患有糖尿病标识'],axis=1)\n",
    "test=test_df\n",
    "\n",
    "train_x,val_x,train_y,val_y=train_test_split(train,train_label,test_size=0.25,random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn的test_score为：0.8495\n",
      "svm的test_score为：0.8119\n",
      "lr的test_score为：0.7509\n",
      "cart的test_score为：0.9301\n",
      "rfc的test_score为：0.9461\n",
      "gdbt的test_score为：0.9434\n",
      "hgb的test_score为：0.9412\n",
      "xgb的test_score为：0.9403\n",
      "lgb的test_score为：0.9406\n",
      "cgb的test_score为：0.9411\n"
     ]
    }
   ],
   "source": [
    "model={}\n",
    "model['knn']=KNeighborsClassifier()\n",
    "model['svm']=svm.SVC()\n",
    "model['lr']=LogisticRegression()\n",
    "model['cart']=DecisionTreeClassifier()\n",
    "model['rfc']=RandomForestClassifier()\n",
    "model['gdbt']=GradientBoostingClassifier()\n",
    "model['hgb']=HistGradientBoostingClassifier()\n",
    "model['xgb']=XGBClassifier()\n",
    "model['lgb']=LGBMClassifier()\n",
    "model['cgb']=CatBoostClassifier(verbose=False)\n",
    "\n",
    "for i in model:\n",
    "    model[i].fit(train_x,train_y)\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=2022)\n",
    "    score=cross_validate(model[i],train,\n",
    "                        train_label,\n",
    "                        cv=cv,\n",
    "                        scoring='f1',\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True\n",
    "                        )\n",
    "    #print(f'{i}的train_score为：{round(score[\"train_score\"].mean(),4)}')\n",
    "    print(f'{i}的test_score为：{round(score[\"test_score\"].mean(),4)}')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **模型优化对比**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn的f1_score为：0.8495\n",
      "svm的f1_score为：0.8119\n",
      "lr的f1_score为：0.7509\n",
      "cart的f1_score为：0.93\n",
      "rfc的f1_score为：0.9456\n",
      "gdbt的f1_score为：0.9305\n",
      "hgb的f1_score为：0.9458\n",
      "xgb的f1_score为：0.944\n",
      "lgb的f1_score为：0.9409\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model['rfc']=RandomForestClassifier(max_depth=11\n",
    "                                    ,min_samples_leaf=5\n",
    "                                    ,n_estimators=151\n",
    "                                    ,max_features=9\n",
    "                                    ,random_state=2022\n",
    "                                    )\n",
    "model['gdbt']=GradientBoostingClassifier(n_estimators=131\n",
    "                                        ,max_depth=15\n",
    "                                        ,max_features=19\n",
    "                                        ,learning_rate=0.1\n",
    "                                        ,random_state=2022\n",
    "                                        )\n",
    "model['hgb']=HistGradientBoostingClassifier(max_iter =84                  \n",
    "                                            ,learning_rate=0.01\n",
    "                                            ,max_depth=29\n",
    "                                            ,min_samples_leaf=2\n",
    "                                            ,random_state=2022\n",
    "                                            ,l2_regularization=0\n",
    "                                            )\n",
    "model['xgb']=XGBClassifier( gamma=0,\n",
    "                            n_estimators=119,\n",
    "                            booster=\"dart\",\n",
    "                            learning_rate=0.06,\n",
    "                            random_state=2022,\n",
    "                            max_depth=6,\n",
    "                            #max_feature=\"auto\",\n",
    "                            objective='binary:logistic',\n",
    "                            #subsample=0.8,\n",
    "                            #reg_lambda=0.4,\n",
    "                            #colsample_bytree=0.4,\n",
    "                            #colsample_bynode=0.4,\n",
    "                            #min_impurity_decrease = 3,\n",
    "                            #tree_method='gpu_hist',\n",
    "                            #gpu_id=0\n",
    "                            )\n",
    "model['lgb']=LGBMClassifier(gama=0,\n",
    "                            n_estimators=181,\n",
    "                            learning_rate=0.01,\n",
    "                            random_state=2022,\n",
    "                            max_depth=6,\n",
    "                            max_feature=13,\n",
    "                            objective='binary',\n",
    "                            subsample=0.8,\n",
    "                            reg_lambda=0.4,\n",
    "                            min_impurity_decrease = 3,\n",
    "                            device=\"GPU\",\n",
    "                            gpu_platform_id=0,\n",
    "                            gpu_device=0\n",
    "                            )\n",
    "model['cgb']=CatBoostClassifier(n_estimators=100,\n",
    "                                max_depth=16,\n",
    "                                #l2_leaf_reg=4,\n",
    "                                verbose=False,\n",
    "                                #task_type=\"GPU\",\n",
    "                                #devices='0:1'\n",
    "                                )\n",
    "\n",
    "for i in model:\n",
    "    model[i].fit(train,train_label)\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=2022)\n",
    "    score = cross_validate(model[i],train,train_label\n",
    "                                     ,scoring=\"f1\"\n",
    "                                     ,cv=cv #交叉验证模式\n",
    "                                     ,verbose=False #是否打印进程\n",
    "                                     ,n_jobs=-1 #线程数\n",
    "                                     ,error_score='raise'\n",
    "                                    )\n",
    "    print(f'{i}的f1_score为：{round(score[\"test_score\"].mean(),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 单模构建与优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "XGB调优-原生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params1的分数是: 0.93595\n",
      "params2的分数是: 0.93555\n",
      "params3的分数是: 0.94375\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "dtrain = xgb.DMatrix(train_x, train_y)\n",
    "dtest = xgb.DMatrix(val_x,val_y)\n",
    "\n",
    "params1 = {\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"max_depth\":6,\n",
    "        \"eta\":0.05,\n",
    "        \"gamma\":0,\n",
    "        \"lambda\":1,\n",
    "        \"alpha\":0,\n",
    "        \"colsample_bytree\":1,\n",
    "        \"colsample_bylevel\":0.4,\n",
    "        \"colsample_bynode\":1,\n",
    "        \"eval_metric\":\"error\",\n",
    "        }\n",
    "cv_result1 = xgb.cv(params1,dtrain,num_boost_round=100,nfold=5,seed=1412)\n",
    "params2 = {\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"max_depth\":6,\n",
    "        \"eta\":0.1,\n",
    "        \"gamma\":0.05,\n",
    "        \"lambda\":1,\n",
    "        \"alpha\":0,\n",
    "        \"colsample_bytree\":1,\n",
    "        \"colsample_bylevel\":0.4,\n",
    "        \"colsample_bynode\":1,\n",
    "        \"eval_metric\":\"error\",\n",
    "        }\n",
    "cv_result2 = xgb.cv(params2,dtrain,num_boost_round=100,nfold=5,seed=1412)\n",
    "\n",
    "params3 = {\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"max_depth\":6,\n",
    "        \"eta\":0.01,\n",
    "        \"gamma\":0.05,\n",
    "        \"lambda\":1,\n",
    "        \"alpha\":0,\n",
    "        \"colsample_bytree\":1,\n",
    "        \"colsample_bylevel\":0.4,\n",
    "        \"colsample_bynode\":1,\n",
    "        \"eval_metric\":\"error\",\n",
    "        }\n",
    "cv_result3 = xgb.cv(params3,dtrain,num_boost_round=100,nfold=5,seed=1412)\n",
    "\n",
    "params = [params1,params2,params3]\n",
    "label = ['params1','params2','params3']\n",
    "for i,label in zip(params,label):\n",
    "    import xgboost as xgb\n",
    "    from sklearn.metrics import f1_score\n",
    "    xgb = xgb.train(i,dtrain,num_boost_round=200)\n",
    "    Y_predict = pd.DataFrame(xgb.predict(dtest))\n",
    "    #因为竞赛需要提交最后的预测判断，而模型给出的预测结果是概率，因此我们认为概率>0.5的即该患者有糖尿病，概率<=0.5的没有糖尿病\n",
    "    Y_predict=Y_predict.loc[:,0].apply(lambda x:1 if x>0.5 else 0)\n",
    "    print(f'{label}的分数是: {round(f1_score(val_y,Y_predict),5)}')\n",
    "\n",
    "plt.style.use('seaborn-dark')\n",
    "fig,ax = plt.subplots(1,figsize=(15,8))\n",
    "ax.set_ylim(top=0.2)\n",
    "ax.grid()\n",
    "ax.plot(range(1,101),cv_result1.iloc[:,0],c=\"red\",label=\"train,red\")\n",
    "ax.plot(range(1,101),cv_result1.iloc[:,2],c=\"red\",label=\"test,red\",alpha=0.7)\n",
    "ax.plot(range(1,101),cv_result2.iloc[:,0],c=\"green\",label=\"train,last\")\n",
    "ax.plot(range(1,101),cv_result2.iloc[:,2],c=\"green\",label=\"test,last\",alpha=0.7)\n",
    "ax.plot(range(1,101),cv_result3.iloc[:,0],c=\"blue\",label=\"train,this\")\n",
    "ax.plot(range(1,101),cv_result3.iloc[:,2],c=\"blue\",label=\"test,this\",alpha=0.7)\n",
    "ax.legend(fontsize=\"xx-large\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "LGB调优-原生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "dtrain = lgb.Dataset(train_x, train_y)\n",
    "dtest = lgb.Dataset(val_x,val_y)\n",
    "\n",
    "eta = np.arange(0.01,0.5,0.01)\n",
    "score = []\n",
    "for i in eta:\n",
    "    import lightgbm as lgb\n",
    "    params4 = {\n",
    "            'objective':'binary',\n",
    "            'eta':i,\n",
    "            'max_depth':13,\n",
    "            'num_leaves':7,\n",
    "            'lambda_l2':0.8,\n",
    "            'min_data_in_leaf':2,\n",
    "            'subsample':0.8,\n",
    "            'bagging_freq':1,\n",
    "            'feature_fraction':0.8,\n",
    "        #    'slient':True,\n",
    "            'seed': 1000,\n",
    "            }\n",
    "\n",
    "    num_boost_round=100\n",
    "    lgb = lgb.train(params4,dtrain,num_boost_round)\n",
    "    lgb.predict(val_x)\n",
    "    Y_predict = pd.DataFrame(lgb.predict(val_x))\n",
    "    #因为竞赛需要提交最后的预测判断，而模型给出的预测结果是概率，因此我们认为概率>0.5的即该患者有糖尿病，概率<=0.5的没有糖尿病\n",
    "    Y_predict = Y_predict.loc[:,0].apply(lambda x:1 if x>0.5 else 0)\n",
    "    from sklearn.metrics import f1_score\n",
    "    score.append(round(f1_score(val_y,Y_predict),5))\n",
    "    #print(f'f1_score: {round(f1_score(val_y,Y_predict),5)}')\n",
    "\n",
    "plt.style.use('seaborn-dark')\n",
    "fig,ax = plt.subplots(1,figsize=(15,8))\n",
    "#ax.set_ylim(top=1,bottom=0.8)\n",
    "plt.plot(eta,score,color='g',label='eta')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "dtrain = lgb.Dataset(train_x, train_y)\n",
    "dtest = lgb.Dataset(val_x,val_y)\n",
    "\n",
    "max_depth = range(1,20,1)\n",
    "score = []\n",
    "for i in max_depth:\n",
    "    import lightgbm as lgb\n",
    "    params4 = {\n",
    "            'objective':'binary',\n",
    "            'eta':0.05,\n",
    "            'max_depth':i,\n",
    "            'num_leaves':31,\n",
    "            'lambda_l2':0.8,\n",
    "            'min_data_in_leaf':2,\n",
    "            'subsample':0.8,\n",
    "            'bagging_freq':1,\n",
    "            'feature_fraction':0.8,\n",
    "        #    'slient':True,\n",
    "            'seed': 1000\n",
    "            }\n",
    "\n",
    "    num_boost_round=100\n",
    "    lgb = lgb.train(params4,dtrain,num_boost_round)\n",
    "    lgb.predict(val_x)\n",
    "    Y_predict = pd.DataFrame(lgb.predict(val_x))\n",
    "    #因为竞赛需要提交最后的预测判断，而模型给出的预测结果是概率，因此我们认为概率>0.5的即该患者有糖尿病，概率<=0.5的没有糖尿病\n",
    "    Y_predict = Y_predict.loc[:,0].apply(lambda x:1 if x>0.5 else 0)\n",
    "    from sklearn.metrics import f1_score\n",
    "    score.append(round(f1_score(val_y,Y_predict),5))\n",
    "    #print(f'f1_score: {round(f1_score(val_y,Y_predict),5)}')\n",
    "\n",
    "plt.style.use('seaborn-dark')\n",
    "fig,ax = plt.subplots(1,figsize=(15,8))\n",
    "#ax.set_ylim(top=1,bottom=0.8)\n",
    "plt.plot(max_depth,score,color='g',label='max_drpth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1936, number of negative: 3134\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1322\n",
      "[LightGBM] [Info] Number of data points in the train set: 5070, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.381854 -> initscore=-0.481686\n",
      "[LightGBM] [Info] Start training from score -0.481686\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "def select_by_lgb(train_data,train_label,test_data,random_state=2022,metric='auc',num_round=300):\n",
    "    clf=lightgbm\n",
    "    train_matrix=clf.Dataset(train_data,label=train_label)\n",
    "\n",
    "    params={\n",
    "            'boosting_type': 'gbdt',  \n",
    "            'objective': 'binary',\n",
    "            'learning_rate': 0.1,\n",
    "            'metric': metric,\n",
    "            'random_state': 2020,\n",
    "            'n_jobs':-1 }\n",
    "    model=clf.train(params,train_matrix,num_round)\n",
    "    pre_y=model.predict(test_data)\n",
    "    return pre_y\n",
    "\n",
    "\n",
    "#输出预测值   \n",
    "test_data=select_by_lgb(train,train_label,test)\n",
    "pre_y=pd.DataFrame(test_data)\n",
    "pre_y['label']=pre_y[0].apply(lambda x:1 if x>0.5 else 0)\n",
    "result=pd.read_csv('提交示例.csv')\n",
    "result['label']=pre_y['label']\n",
    "result.to_csv('lgb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1547, number of negative: 2509\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1312\n",
      "[LightGBM] [Info] Number of data points in the train set: 4056, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.381410 -> initscore=-0.483567\n",
      "[LightGBM] [Info] Start training from score -0.483567\n",
      "[1]\tvalid_0's auc: 0.986998\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.988035\n",
      "[3]\tvalid_0's auc: 0.988193\n",
      "[4]\tvalid_0's auc: 0.98816\n",
      "[5]\tvalid_0's auc: 0.988156\n",
      "[6]\tvalid_0's auc: 0.988175\n",
      "[7]\tvalid_0's auc: 0.98823\n",
      "[8]\tvalid_0's auc: 0.988364\n",
      "[9]\tvalid_0's auc: 0.988446\n",
      "[10]\tvalid_0's auc: 0.988623\n",
      "[11]\tvalid_0's auc: 0.990842\n",
      "[12]\tvalid_0's auc: 0.990926\n",
      "[13]\tvalid_0's auc: 0.990873\n",
      "[14]\tvalid_0's auc: 0.990988\n",
      "[15]\tvalid_0's auc: 0.991064\n",
      "[16]\tvalid_0's auc: 0.991097\n",
      "[17]\tvalid_0's auc: 0.991079\n",
      "[18]\tvalid_0's auc: 0.991038\n",
      "[19]\tvalid_0's auc: 0.991831\n",
      "[20]\tvalid_0's auc: 0.991846\n",
      "[21]\tvalid_0's auc: 0.991833\n",
      "[22]\tvalid_0's auc: 0.991881\n",
      "[23]\tvalid_0's auc: 0.991852\n",
      "[24]\tvalid_0's auc: 0.992255\n",
      "[25]\tvalid_0's auc: 0.992056\n",
      "[26]\tvalid_0's auc: 0.992006\n",
      "[27]\tvalid_0's auc: 0.991965\n",
      "[28]\tvalid_0's auc: 0.992006\n",
      "[29]\tvalid_0's auc: 0.991986\n",
      "[30]\tvalid_0's auc: 0.992006\n",
      "[31]\tvalid_0's auc: 0.99214\n",
      "[32]\tvalid_0's auc: 0.992019\n",
      "[33]\tvalid_0's auc: 0.992514\n",
      "[34]\tvalid_0's auc: 0.992454\n",
      "[35]\tvalid_0's auc: 0.991591\n",
      "[36]\tvalid_0's auc: 0.991299\n",
      "[37]\tvalid_0's auc: 0.992093\n",
      "[38]\tvalid_0's auc: 0.99207\n",
      "[39]\tvalid_0's auc: 0.991848\n",
      "[40]\tvalid_0's auc: 0.991856\n",
      "[41]\tvalid_0's auc: 0.991774\n",
      "[42]\tvalid_0's auc: 0.991679\n",
      "[43]\tvalid_0's auc: 0.991716\n",
      "[44]\tvalid_0's auc: 0.991354\n",
      "[45]\tvalid_0's auc: 0.991416\n",
      "[46]\tvalid_0's auc: 0.991798\n",
      "[47]\tvalid_0's auc: 0.99163\n",
      "[48]\tvalid_0's auc: 0.991313\n",
      "[49]\tvalid_0's auc: 0.991268\n",
      "[50]\tvalid_0's auc: 0.991432\n",
      "[51]\tvalid_0's auc: 0.991256\n",
      "[52]\tvalid_0's auc: 0.991288\n",
      "[53]\tvalid_0's auc: 0.991239\n",
      "[54]\tvalid_0's auc: 0.991272\n",
      "[55]\tvalid_0's auc: 0.991667\n",
      "[56]\tvalid_0's auc: 0.991914\n",
      "[57]\tvalid_0's auc: 0.991889\n",
      "[58]\tvalid_0's auc: 0.992021\n",
      "[59]\tvalid_0's auc: 0.992132\n",
      "[60]\tvalid_0's auc: 0.992313\n",
      "[61]\tvalid_0's auc: 0.992288\n",
      "[62]\tvalid_0's auc: 0.992403\n",
      "[63]\tvalid_0's auc: 0.99237\n",
      "[64]\tvalid_0's auc: 0.992391\n",
      "[65]\tvalid_0's auc: 0.992477\n",
      "[66]\tvalid_0's auc: 0.992506\n",
      "[67]\tvalid_0's auc: 0.992543\n",
      "[68]\tvalid_0's auc: 0.992856\n",
      "[69]\tvalid_0's auc: 0.992753\n",
      "[70]\tvalid_0's auc: 0.992786\n",
      "[71]\tvalid_0's auc: 0.99288\n",
      "[72]\tvalid_0's auc: 0.99288\n",
      "[73]\tvalid_0's auc: 0.99295\n",
      "[74]\tvalid_0's auc: 0.992979\n",
      "[75]\tvalid_0's auc: 0.992934\n",
      "[76]\tvalid_0's auc: 0.992946\n",
      "[77]\tvalid_0's auc: 0.992864\n",
      "[78]\tvalid_0's auc: 0.992802\n",
      "[79]\tvalid_0's auc: 0.992856\n",
      "[80]\tvalid_0's auc: 0.992786\n",
      "[81]\tvalid_0's auc: 0.992819\n",
      "[82]\tvalid_0's auc: 0.992839\n",
      "[83]\tvalid_0's auc: 0.992876\n",
      "[84]\tvalid_0's auc: 0.992856\n",
      "[85]\tvalid_0's auc: 0.992819\n",
      "[86]\tvalid_0's auc: 0.992728\n",
      "[87]\tvalid_0's auc: 0.99272\n",
      "[88]\tvalid_0's auc: 0.992732\n",
      "[89]\tvalid_0's auc: 0.992839\n",
      "[90]\tvalid_0's auc: 0.992749\n",
      "[91]\tvalid_0's auc: 0.992823\n",
      "[92]\tvalid_0's auc: 0.992744\n",
      "[93]\tvalid_0's auc: 0.992814\n",
      "[94]\tvalid_0's auc: 0.992843\n",
      "[95]\tvalid_0's auc: 0.992806\n",
      "[96]\tvalid_0's auc: 0.992835\n",
      "[97]\tvalid_0's auc: 0.992839\n",
      "[98]\tvalid_0's auc: 0.992827\n",
      "[99]\tvalid_0's auc: 0.992769\n",
      "[100]\tvalid_0's auc: 0.992707\n",
      "[101]\tvalid_0's auc: 0.992707\n",
      "[102]\tvalid_0's auc: 0.992633\n",
      "[103]\tvalid_0's auc: 0.992596\n",
      "[104]\tvalid_0's auc: 0.992695\n",
      "[105]\tvalid_0's auc: 0.992592\n",
      "[106]\tvalid_0's auc: 0.992613\n",
      "[107]\tvalid_0's auc: 0.992744\n",
      "[108]\tvalid_0's auc: 0.992794\n",
      "[109]\tvalid_0's auc: 0.992638\n",
      "[110]\tvalid_0's auc: 0.992699\n",
      "[111]\tvalid_0's auc: 0.99267\n",
      "[112]\tvalid_0's auc: 0.992601\n",
      "[113]\tvalid_0's auc: 0.992707\n",
      "[114]\tvalid_0's auc: 0.99272\n",
      "[115]\tvalid_0's auc: 0.992831\n",
      "[116]\tvalid_0's auc: 0.992724\n",
      "[117]\tvalid_0's auc: 0.992703\n",
      "[118]\tvalid_0's auc: 0.99265\n",
      "[119]\tvalid_0's auc: 0.992633\n",
      "[120]\tvalid_0's auc: 0.992629\n",
      "[121]\tvalid_0's auc: 0.992654\n",
      "[122]\tvalid_0's auc: 0.992683\n",
      "[123]\tvalid_0's auc: 0.992675\n",
      "[124]\tvalid_0's auc: 0.992601\n",
      "[125]\tvalid_0's auc: 0.992646\n",
      "[126]\tvalid_0's auc: 0.992531\n",
      "[127]\tvalid_0's auc: 0.992547\n",
      "[128]\tvalid_0's auc: 0.992473\n",
      "[129]\tvalid_0's auc: 0.992452\n",
      "[130]\tvalid_0's auc: 0.992444\n",
      "[131]\tvalid_0's auc: 0.992358\n",
      "[132]\tvalid_0's auc: 0.992448\n",
      "[133]\tvalid_0's auc: 0.992498\n",
      "[134]\tvalid_0's auc: 0.992465\n",
      "[135]\tvalid_0's auc: 0.992432\n",
      "[136]\tvalid_0's auc: 0.992473\n",
      "[137]\tvalid_0's auc: 0.992572\n",
      "[138]\tvalid_0's auc: 0.992494\n",
      "[139]\tvalid_0's auc: 0.992547\n",
      "[140]\tvalid_0's auc: 0.992547\n",
      "[141]\tvalid_0's auc: 0.992526\n",
      "[142]\tvalid_0's auc: 0.992415\n",
      "[143]\tvalid_0's auc: 0.992424\n",
      "[144]\tvalid_0's auc: 0.992477\n",
      "[145]\tvalid_0's auc: 0.992428\n",
      "[146]\tvalid_0's auc: 0.992485\n",
      "[147]\tvalid_0's auc: 0.992469\n",
      "[148]\tvalid_0's auc: 0.992457\n",
      "[149]\tvalid_0's auc: 0.992481\n",
      "[150]\tvalid_0's auc: 0.992391\n",
      "[151]\tvalid_0's auc: 0.9923\n",
      "[152]\tvalid_0's auc: 0.992251\n",
      "[153]\tvalid_0's auc: 0.992259\n",
      "[154]\tvalid_0's auc: 0.992288\n",
      "[155]\tvalid_0's auc: 0.992292\n",
      "[156]\tvalid_0's auc: 0.992329\n",
      "[157]\tvalid_0's auc: 0.992395\n",
      "[158]\tvalid_0's auc: 0.992411\n",
      "[159]\tvalid_0's auc: 0.992337\n",
      "[160]\tvalid_0's auc: 0.992329\n",
      "[161]\tvalid_0's auc: 0.992325\n",
      "[162]\tvalid_0's auc: 0.992378\n",
      "[163]\tvalid_0's auc: 0.99242\n",
      "[164]\tvalid_0's auc: 0.99242\n",
      "[165]\tvalid_0's auc: 0.992399\n",
      "[166]\tvalid_0's auc: 0.992391\n",
      "[167]\tvalid_0's auc: 0.992407\n",
      "[168]\tvalid_0's auc: 0.992333\n",
      "[169]\tvalid_0's auc: 0.992329\n",
      "[170]\tvalid_0's auc: 0.99235\n",
      "[171]\tvalid_0's auc: 0.992383\n",
      "[172]\tvalid_0's auc: 0.992461\n",
      "[173]\tvalid_0's auc: 0.99242\n",
      "[174]\tvalid_0's auc: 0.992432\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.992979\n",
      "[LightGBM] [Info] Number of positive: 1550, number of negative: 2506\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1308\n",
      "[LightGBM] [Info] Number of data points in the train set: 4056, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382150 -> initscore=-0.480433\n",
      "[LightGBM] [Info] Start training from score -0.480433\n",
      "[1]\tvalid_0's auc: 0.983095\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.985104\n",
      "[3]\tvalid_0's auc: 0.984574\n",
      "[4]\tvalid_0's auc: 0.98697\n",
      "[5]\tvalid_0's auc: 0.987319\n",
      "[6]\tvalid_0's auc: 0.987362\n",
      "[7]\tvalid_0's auc: 0.987422\n",
      "[8]\tvalid_0's auc: 0.987208\n",
      "[9]\tvalid_0's auc: 0.987224\n",
      "[10]\tvalid_0's auc: 0.987109\n",
      "[11]\tvalid_0's auc: 0.987191\n",
      "[12]\tvalid_0's auc: 0.987373\n",
      "[13]\tvalid_0's auc: 0.987424\n",
      "[14]\tvalid_0's auc: 0.988581\n",
      "[15]\tvalid_0's auc: 0.988585\n",
      "[16]\tvalid_0's auc: 0.988816\n",
      "[17]\tvalid_0's auc: 0.988854\n",
      "[18]\tvalid_0's auc: 0.98894\n",
      "[19]\tvalid_0's auc: 0.988833\n",
      "[20]\tvalid_0's auc: 0.988827\n",
      "[21]\tvalid_0's auc: 0.988938\n",
      "[22]\tvalid_0's auc: 0.988992\n",
      "[23]\tvalid_0's auc: 0.989012\n",
      "[24]\tvalid_0's auc: 0.989012\n",
      "[25]\tvalid_0's auc: 0.989004\n",
      "[26]\tvalid_0's auc: 0.988854\n",
      "[27]\tvalid_0's auc: 0.988812\n",
      "[28]\tvalid_0's auc: 0.9888\n",
      "[29]\tvalid_0's auc: 0.989379\n",
      "[30]\tvalid_0's auc: 0.989243\n",
      "[31]\tvalid_0's auc: 0.989439\n",
      "[32]\tvalid_0's auc: 0.990667\n",
      "[33]\tvalid_0's auc: 0.991036\n",
      "[34]\tvalid_0's auc: 0.991403\n",
      "[35]\tvalid_0's auc: 0.9913\n",
      "[36]\tvalid_0's auc: 0.991506\n",
      "[37]\tvalid_0's auc: 0.991527\n",
      "[38]\tvalid_0's auc: 0.991492\n",
      "[39]\tvalid_0's auc: 0.991339\n",
      "[40]\tvalid_0's auc: 0.991384\n",
      "[41]\tvalid_0's auc: 0.991434\n",
      "[42]\tvalid_0's auc: 0.991504\n",
      "[43]\tvalid_0's auc: 0.991549\n",
      "[44]\tvalid_0's auc: 0.991459\n",
      "[45]\tvalid_0's auc: 0.991467\n",
      "[46]\tvalid_0's auc: 0.991624\n",
      "[47]\tvalid_0's auc: 0.991607\n",
      "[48]\tvalid_0's auc: 0.991611\n",
      "[49]\tvalid_0's auc: 0.99182\n",
      "[50]\tvalid_0's auc: 0.991989\n",
      "[51]\tvalid_0's auc: 0.99184\n",
      "[52]\tvalid_0's auc: 0.991972\n",
      "[53]\tvalid_0's auc: 0.991968\n",
      "[54]\tvalid_0's auc: 0.992026\n",
      "[55]\tvalid_0's auc: 0.992133\n",
      "[56]\tvalid_0's auc: 0.992022\n",
      "[57]\tvalid_0's auc: 0.991997\n",
      "[58]\tvalid_0's auc: 0.992063\n",
      "[59]\tvalid_0's auc: 0.992133\n",
      "[60]\tvalid_0's auc: 0.99222\n",
      "[61]\tvalid_0's auc: 0.992063\n",
      "[62]\tvalid_0's auc: 0.992125\n",
      "[63]\tvalid_0's auc: 0.992232\n",
      "[64]\tvalid_0's auc: 0.992253\n",
      "[65]\tvalid_0's auc: 0.992261\n",
      "[66]\tvalid_0's auc: 0.992277\n",
      "[67]\tvalid_0's auc: 0.992298\n",
      "[68]\tvalid_0's auc: 0.992154\n",
      "[69]\tvalid_0's auc: 0.992224\n",
      "[70]\tvalid_0's auc: 0.992195\n",
      "[71]\tvalid_0's auc: 0.992224\n",
      "[72]\tvalid_0's auc: 0.99222\n",
      "[73]\tvalid_0's auc: 0.9921\n",
      "[74]\tvalid_0's auc: 0.992141\n",
      "[75]\tvalid_0's auc: 0.992046\n",
      "[76]\tvalid_0's auc: 0.992022\n",
      "[77]\tvalid_0's auc: 0.992079\n",
      "[78]\tvalid_0's auc: 0.992067\n",
      "[79]\tvalid_0's auc: 0.992071\n",
      "[80]\tvalid_0's auc: 0.992018\n",
      "[81]\tvalid_0's auc: 0.992075\n",
      "[82]\tvalid_0's auc: 0.992051\n",
      "[83]\tvalid_0's auc: 0.992071\n",
      "[84]\tvalid_0's auc: 0.991989\n",
      "[85]\tvalid_0's auc: 0.991947\n",
      "[86]\tvalid_0's auc: 0.992001\n",
      "[87]\tvalid_0's auc: 0.991952\n",
      "[88]\tvalid_0's auc: 0.99189\n",
      "[89]\tvalid_0's auc: 0.991943\n",
      "[90]\tvalid_0's auc: 0.99203\n",
      "[91]\tvalid_0's auc: 0.992009\n",
      "[92]\tvalid_0's auc: 0.992009\n",
      "[93]\tvalid_0's auc: 0.992018\n",
      "[94]\tvalid_0's auc: 0.991976\n",
      "[95]\tvalid_0's auc: 0.991964\n",
      "[96]\tvalid_0's auc: 0.991997\n",
      "[97]\tvalid_0's auc: 0.99196\n",
      "[98]\tvalid_0's auc: 0.991931\n",
      "[99]\tvalid_0's auc: 0.991898\n",
      "[100]\tvalid_0's auc: 0.992009\n",
      "[101]\tvalid_0's auc: 0.992018\n",
      "[102]\tvalid_0's auc: 0.991997\n",
      "[103]\tvalid_0's auc: 0.991931\n",
      "[104]\tvalid_0's auc: 0.991894\n",
      "[105]\tvalid_0's auc: 0.991939\n",
      "[106]\tvalid_0's auc: 0.99177\n",
      "[107]\tvalid_0's auc: 0.991667\n",
      "[108]\tvalid_0's auc: 0.991787\n",
      "[109]\tvalid_0's auc: 0.991824\n",
      "[110]\tvalid_0's auc: 0.991803\n",
      "[111]\tvalid_0's auc: 0.991683\n",
      "[112]\tvalid_0's auc: 0.991758\n",
      "[113]\tvalid_0's auc: 0.991729\n",
      "[114]\tvalid_0's auc: 0.991754\n",
      "[115]\tvalid_0's auc: 0.991766\n",
      "[116]\tvalid_0's auc: 0.99182\n",
      "[117]\tvalid_0's auc: 0.991824\n",
      "[118]\tvalid_0's auc: 0.991815\n",
      "[119]\tvalid_0's auc: 0.991881\n",
      "[120]\tvalid_0's auc: 0.99184\n",
      "[121]\tvalid_0's auc: 0.991824\n",
      "[122]\tvalid_0's auc: 0.991766\n",
      "[123]\tvalid_0's auc: 0.991766\n",
      "[124]\tvalid_0's auc: 0.991782\n",
      "[125]\tvalid_0's auc: 0.991774\n",
      "[126]\tvalid_0's auc: 0.991758\n",
      "[127]\tvalid_0's auc: 0.991811\n",
      "[128]\tvalid_0's auc: 0.991782\n",
      "[129]\tvalid_0's auc: 0.991799\n",
      "[130]\tvalid_0's auc: 0.991708\n",
      "[131]\tvalid_0's auc: 0.991712\n",
      "[132]\tvalid_0's auc: 0.991762\n",
      "[133]\tvalid_0's auc: 0.991803\n",
      "[134]\tvalid_0's auc: 0.991811\n",
      "[135]\tvalid_0's auc: 0.991754\n",
      "[136]\tvalid_0's auc: 0.9917\n",
      "[137]\tvalid_0's auc: 0.991737\n",
      "[138]\tvalid_0's auc: 0.9917\n",
      "[139]\tvalid_0's auc: 0.991729\n",
      "[140]\tvalid_0's auc: 0.991725\n",
      "[141]\tvalid_0's auc: 0.991688\n",
      "[142]\tvalid_0's auc: 0.991683\n",
      "[143]\tvalid_0's auc: 0.991613\n",
      "[144]\tvalid_0's auc: 0.991617\n",
      "[145]\tvalid_0's auc: 0.991593\n",
      "[146]\tvalid_0's auc: 0.991564\n",
      "[147]\tvalid_0's auc: 0.991543\n",
      "[148]\tvalid_0's auc: 0.991597\n",
      "[149]\tvalid_0's auc: 0.991601\n",
      "[150]\tvalid_0's auc: 0.991622\n",
      "[151]\tvalid_0's auc: 0.991688\n",
      "[152]\tvalid_0's auc: 0.991683\n",
      "[153]\tvalid_0's auc: 0.991704\n",
      "[154]\tvalid_0's auc: 0.991758\n",
      "[155]\tvalid_0's auc: 0.991741\n",
      "[156]\tvalid_0's auc: 0.991741\n",
      "[157]\tvalid_0's auc: 0.991762\n",
      "[158]\tvalid_0's auc: 0.991729\n",
      "[159]\tvalid_0's auc: 0.991749\n",
      "[160]\tvalid_0's auc: 0.991741\n",
      "[161]\tvalid_0's auc: 0.991774\n",
      "[162]\tvalid_0's auc: 0.991803\n",
      "[163]\tvalid_0's auc: 0.991774\n",
      "[164]\tvalid_0's auc: 0.991803\n",
      "[165]\tvalid_0's auc: 0.99184\n",
      "[166]\tvalid_0's auc: 0.991807\n",
      "[167]\tvalid_0's auc: 0.99177\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.992298\n",
      "[LightGBM] [Info] Number of positive: 1549, number of negative: 2507\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1306\n",
      "[LightGBM] [Info] Number of data points in the train set: 4056, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.381903 -> initscore=-0.481477\n",
      "[LightGBM] [Info] Start training from score -0.481477\n",
      "[1]\tvalid_0's auc: 0.986625\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.987237\n",
      "[3]\tvalid_0's auc: 0.987702\n",
      "[4]\tvalid_0's auc: 0.987593\n",
      "[5]\tvalid_0's auc: 0.987696\n",
      "[6]\tvalid_0's auc: 0.987488\n",
      "[7]\tvalid_0's auc: 0.986499\n",
      "[8]\tvalid_0's auc: 0.986783\n",
      "[9]\tvalid_0's auc: 0.986831\n",
      "[10]\tvalid_0's auc: 0.98701\n",
      "[11]\tvalid_0's auc: 0.987259\n",
      "[12]\tvalid_0's auc: 0.987195\n",
      "[13]\tvalid_0's auc: 0.987268\n",
      "[14]\tvalid_0's auc: 0.98728\n",
      "[15]\tvalid_0's auc: 0.987309\n",
      "[16]\tvalid_0's auc: 0.987383\n",
      "[17]\tvalid_0's auc: 0.987255\n",
      "[18]\tvalid_0's auc: 0.987059\n",
      "[19]\tvalid_0's auc: 0.987323\n",
      "[20]\tvalid_0's auc: 0.987377\n",
      "[21]\tvalid_0's auc: 0.987385\n",
      "[22]\tvalid_0's auc: 0.987239\n",
      "[23]\tvalid_0's auc: 0.987257\n",
      "[24]\tvalid_0's auc: 0.987261\n",
      "[25]\tvalid_0's auc: 0.987177\n",
      "[26]\tvalid_0's auc: 0.987029\n",
      "[27]\tvalid_0's auc: 0.989394\n",
      "[28]\tvalid_0's auc: 0.990334\n",
      "[29]\tvalid_0's auc: 0.990406\n",
      "[30]\tvalid_0's auc: 0.990404\n",
      "[31]\tvalid_0's auc: 0.990453\n",
      "[32]\tvalid_0's auc: 0.99047\n",
      "[33]\tvalid_0's auc: 0.991568\n",
      "[34]\tvalid_0's auc: 0.991737\n",
      "[35]\tvalid_0's auc: 0.991655\n",
      "[36]\tvalid_0's auc: 0.99165\n",
      "[37]\tvalid_0's auc: 0.991601\n",
      "[38]\tvalid_0's auc: 0.99158\n",
      "[39]\tvalid_0's auc: 0.991708\n",
      "[40]\tvalid_0's auc: 0.991659\n",
      "[41]\tvalid_0's auc: 0.991729\n",
      "[42]\tvalid_0's auc: 0.991679\n",
      "[43]\tvalid_0's auc: 0.991692\n",
      "[44]\tvalid_0's auc: 0.991626\n",
      "[45]\tvalid_0's auc: 0.991585\n",
      "[46]\tvalid_0's auc: 0.991482\n",
      "[47]\tvalid_0's auc: 0.991556\n",
      "[48]\tvalid_0's auc: 0.991539\n",
      "[49]\tvalid_0's auc: 0.99149\n",
      "[50]\tvalid_0's auc: 0.991564\n",
      "[51]\tvalid_0's auc: 0.991585\n",
      "[52]\tvalid_0's auc: 0.991519\n",
      "[53]\tvalid_0's auc: 0.991589\n",
      "[54]\tvalid_0's auc: 0.991428\n",
      "[55]\tvalid_0's auc: 0.991593\n",
      "[56]\tvalid_0's auc: 0.991585\n",
      "[57]\tvalid_0's auc: 0.991605\n",
      "[58]\tvalid_0's auc: 0.991638\n",
      "[59]\tvalid_0's auc: 0.99149\n",
      "[60]\tvalid_0's auc: 0.991502\n",
      "[61]\tvalid_0's auc: 0.991605\n",
      "[62]\tvalid_0's auc: 0.991601\n",
      "[63]\tvalid_0's auc: 0.991659\n",
      "[64]\tvalid_0's auc: 0.991552\n",
      "[65]\tvalid_0's auc: 0.99149\n",
      "[66]\tvalid_0's auc: 0.991609\n",
      "[67]\tvalid_0's auc: 0.99163\n",
      "[68]\tvalid_0's auc: 0.991564\n",
      "[69]\tvalid_0's auc: 0.99144\n",
      "[70]\tvalid_0's auc: 0.991378\n",
      "[71]\tvalid_0's auc: 0.991366\n",
      "[72]\tvalid_0's auc: 0.991296\n",
      "[73]\tvalid_0's auc: 0.991242\n",
      "[74]\tvalid_0's auc: 0.991263\n",
      "[75]\tvalid_0's auc: 0.991329\n",
      "[76]\tvalid_0's auc: 0.991308\n",
      "[77]\tvalid_0's auc: 0.991317\n",
      "[78]\tvalid_0's auc: 0.991234\n",
      "[79]\tvalid_0's auc: 0.991238\n",
      "[80]\tvalid_0's auc: 0.991189\n",
      "[81]\tvalid_0's auc: 0.991152\n",
      "[82]\tvalid_0's auc: 0.991214\n",
      "[83]\tvalid_0's auc: 0.991234\n",
      "[84]\tvalid_0's auc: 0.991238\n",
      "[85]\tvalid_0's auc: 0.991222\n",
      "[86]\tvalid_0's auc: 0.991106\n",
      "[87]\tvalid_0's auc: 0.991139\n",
      "[88]\tvalid_0's auc: 0.991102\n",
      "[89]\tvalid_0's auc: 0.991028\n",
      "[90]\tvalid_0's auc: 0.991074\n",
      "[91]\tvalid_0's auc: 0.991065\n",
      "[92]\tvalid_0's auc: 0.99121\n",
      "[93]\tvalid_0's auc: 0.991226\n",
      "[94]\tvalid_0's auc: 0.991111\n",
      "[95]\tvalid_0's auc: 0.991152\n",
      "[96]\tvalid_0's auc: 0.991177\n",
      "[97]\tvalid_0's auc: 0.991164\n",
      "[98]\tvalid_0's auc: 0.991164\n",
      "[99]\tvalid_0's auc: 0.991144\n",
      "[100]\tvalid_0's auc: 0.991119\n",
      "[101]\tvalid_0's auc: 0.991135\n",
      "[102]\tvalid_0's auc: 0.991135\n",
      "[103]\tvalid_0's auc: 0.991119\n",
      "[104]\tvalid_0's auc: 0.991119\n",
      "[105]\tvalid_0's auc: 0.991082\n",
      "[106]\tvalid_0's auc: 0.991008\n",
      "[107]\tvalid_0's auc: 0.990983\n",
      "[108]\tvalid_0's auc: 0.991012\n",
      "[109]\tvalid_0's auc: 0.990946\n",
      "[110]\tvalid_0's auc: 0.990929\n",
      "[111]\tvalid_0's auc: 0.990938\n",
      "[112]\tvalid_0's auc: 0.990818\n",
      "[113]\tvalid_0's auc: 0.990843\n",
      "[114]\tvalid_0's auc: 0.990851\n",
      "[115]\tvalid_0's auc: 0.99081\n",
      "[116]\tvalid_0's auc: 0.990744\n",
      "[117]\tvalid_0's auc: 0.990698\n",
      "[118]\tvalid_0's auc: 0.990661\n",
      "[119]\tvalid_0's auc: 0.990682\n",
      "[120]\tvalid_0's auc: 0.990744\n",
      "[121]\tvalid_0's auc: 0.990777\n",
      "[122]\tvalid_0's auc: 0.990818\n",
      "[123]\tvalid_0's auc: 0.990888\n",
      "[124]\tvalid_0's auc: 0.990863\n",
      "[125]\tvalid_0's auc: 0.990839\n",
      "[126]\tvalid_0's auc: 0.990847\n",
      "[127]\tvalid_0's auc: 0.990806\n",
      "[128]\tvalid_0's auc: 0.990748\n",
      "[129]\tvalid_0's auc: 0.990777\n",
      "[130]\tvalid_0's auc: 0.990814\n",
      "[131]\tvalid_0's auc: 0.99081\n",
      "[132]\tvalid_0's auc: 0.990859\n",
      "[133]\tvalid_0's auc: 0.990769\n",
      "[134]\tvalid_0's auc: 0.990802\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.991737\n",
      "[LightGBM] [Info] Number of positive: 1547, number of negative: 2509\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1306\n",
      "[LightGBM] [Info] Number of data points in the train set: 4056, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.381410 -> initscore=-0.483567\n",
      "[LightGBM] [Info] Start training from score -0.483567\n",
      "[1]\tvalid_0's auc: 0.987155\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.986347\n",
      "[3]\tvalid_0's auc: 0.986616\n",
      "[4]\tvalid_0's auc: 0.988084\n",
      "[5]\tvalid_0's auc: 0.988027\n",
      "[6]\tvalid_0's auc: 0.987854\n",
      "[7]\tvalid_0's auc: 0.988049\n",
      "[8]\tvalid_0's auc: 0.987938\n",
      "[9]\tvalid_0's auc: 0.988239\n",
      "[10]\tvalid_0's auc: 0.988508\n",
      "[11]\tvalid_0's auc: 0.988315\n",
      "[12]\tvalid_0's auc: 0.988539\n",
      "[13]\tvalid_0's auc: 0.988619\n",
      "[14]\tvalid_0's auc: 0.98864\n",
      "[15]\tvalid_0's auc: 0.988714\n",
      "[16]\tvalid_0's auc: 0.988627\n",
      "[17]\tvalid_0's auc: 0.989859\n",
      "[18]\tvalid_0's auc: 0.989723\n",
      "[19]\tvalid_0's auc: 0.989732\n",
      "[20]\tvalid_0's auc: 0.990184\n",
      "[21]\tvalid_0's auc: 0.990322\n",
      "[22]\tvalid_0's auc: 0.990507\n",
      "[23]\tvalid_0's auc: 0.990495\n",
      "[24]\tvalid_0's auc: 0.990628\n",
      "[25]\tvalid_0's auc: 0.99055\n",
      "[26]\tvalid_0's auc: 0.990488\n",
      "[27]\tvalid_0's auc: 0.990746\n",
      "[28]\tvalid_0's auc: 0.990575\n",
      "[29]\tvalid_0's auc: 0.990484\n",
      "[30]\tvalid_0's auc: 0.990344\n",
      "[31]\tvalid_0's auc: 0.990229\n",
      "[32]\tvalid_0's auc: 0.990085\n",
      "[33]\tvalid_0's auc: 0.99002\n",
      "[34]\tvalid_0's auc: 0.989824\n",
      "[35]\tvalid_0's auc: 0.989672\n",
      "[36]\tvalid_0's auc: 0.989647\n",
      "[37]\tvalid_0's auc: 0.989894\n",
      "[38]\tvalid_0's auc: 0.989656\n",
      "[39]\tvalid_0's auc: 0.989639\n",
      "[40]\tvalid_0's auc: 0.989565\n",
      "[41]\tvalid_0's auc: 0.989528\n",
      "[42]\tvalid_0's auc: 0.989435\n",
      "[43]\tvalid_0's auc: 0.989448\n",
      "[44]\tvalid_0's auc: 0.989226\n",
      "[45]\tvalid_0's auc: 0.989427\n",
      "[46]\tvalid_0's auc: 0.989279\n",
      "[47]\tvalid_0's auc: 0.989197\n",
      "[48]\tvalid_0's auc: 0.989246\n",
      "[49]\tvalid_0's auc: 0.989102\n",
      "[50]\tvalid_0's auc: 0.989296\n",
      "[51]\tvalid_0's auc: 0.989156\n",
      "[52]\tvalid_0's auc: 0.98932\n",
      "[53]\tvalid_0's auc: 0.989386\n",
      "[54]\tvalid_0's auc: 0.989012\n",
      "[55]\tvalid_0's auc: 0.988796\n",
      "[56]\tvalid_0's auc: 0.988923\n",
      "[57]\tvalid_0's auc: 0.988841\n",
      "[58]\tvalid_0's auc: 0.988816\n",
      "[59]\tvalid_0's auc: 0.988886\n",
      "[60]\tvalid_0's auc: 0.988948\n",
      "[61]\tvalid_0's auc: 0.988928\n",
      "[62]\tvalid_0's auc: 0.989026\n",
      "[63]\tvalid_0's auc: 0.988878\n",
      "[64]\tvalid_0's auc: 0.988985\n",
      "[65]\tvalid_0's auc: 0.988845\n",
      "[66]\tvalid_0's auc: 0.988886\n",
      "[67]\tvalid_0's auc: 0.988907\n",
      "[68]\tvalid_0's auc: 0.988989\n",
      "[69]\tvalid_0's auc: 0.98889\n",
      "[70]\tvalid_0's auc: 0.988932\n",
      "[71]\tvalid_0's auc: 0.988928\n",
      "[72]\tvalid_0's auc: 0.988985\n",
      "[73]\tvalid_0's auc: 0.988936\n",
      "[74]\tvalid_0's auc: 0.989022\n",
      "[75]\tvalid_0's auc: 0.98903\n",
      "[76]\tvalid_0's auc: 0.989026\n",
      "[77]\tvalid_0's auc: 0.988928\n",
      "[78]\tvalid_0's auc: 0.988956\n",
      "[79]\tvalid_0's auc: 0.988886\n",
      "[80]\tvalid_0's auc: 0.988779\n",
      "[81]\tvalid_0's auc: 0.988845\n",
      "[82]\tvalid_0's auc: 0.988969\n",
      "[83]\tvalid_0's auc: 0.988907\n",
      "[84]\tvalid_0's auc: 0.988899\n",
      "[85]\tvalid_0's auc: 0.988903\n",
      "[86]\tvalid_0's auc: 0.988829\n",
      "[87]\tvalid_0's auc: 0.989022\n",
      "[88]\tvalid_0's auc: 0.989026\n",
      "[89]\tvalid_0's auc: 0.989063\n",
      "[90]\tvalid_0's auc: 0.989141\n",
      "[91]\tvalid_0's auc: 0.988993\n",
      "[92]\tvalid_0's auc: 0.988944\n",
      "[93]\tvalid_0's auc: 0.988923\n",
      "[94]\tvalid_0's auc: 0.988952\n",
      "[95]\tvalid_0's auc: 0.988874\n",
      "[96]\tvalid_0's auc: 0.988771\n",
      "[97]\tvalid_0's auc: 0.988775\n",
      "[98]\tvalid_0's auc: 0.988779\n",
      "[99]\tvalid_0's auc: 0.988738\n",
      "[100]\tvalid_0's auc: 0.988685\n",
      "[101]\tvalid_0's auc: 0.988693\n",
      "[102]\tvalid_0's auc: 0.988512\n",
      "[103]\tvalid_0's auc: 0.988549\n",
      "[104]\tvalid_0's auc: 0.988508\n",
      "[105]\tvalid_0's auc: 0.98857\n",
      "[106]\tvalid_0's auc: 0.988529\n",
      "[107]\tvalid_0's auc: 0.988512\n",
      "[108]\tvalid_0's auc: 0.988438\n",
      "[109]\tvalid_0's auc: 0.988422\n",
      "[110]\tvalid_0's auc: 0.988467\n",
      "[111]\tvalid_0's auc: 0.988438\n",
      "[112]\tvalid_0's auc: 0.988475\n",
      "[113]\tvalid_0's auc: 0.988467\n",
      "[114]\tvalid_0's auc: 0.988422\n",
      "[115]\tvalid_0's auc: 0.988364\n",
      "[116]\tvalid_0's auc: 0.988348\n",
      "[117]\tvalid_0's auc: 0.988327\n",
      "[118]\tvalid_0's auc: 0.988364\n",
      "[119]\tvalid_0's auc: 0.988216\n",
      "[120]\tvalid_0's auc: 0.988274\n",
      "[121]\tvalid_0's auc: 0.988274\n",
      "[122]\tvalid_0's auc: 0.988282\n",
      "[123]\tvalid_0's auc: 0.988343\n",
      "[124]\tvalid_0's auc: 0.988356\n",
      "[125]\tvalid_0's auc: 0.988315\n",
      "[126]\tvalid_0's auc: 0.988352\n",
      "[127]\tvalid_0's auc: 0.98838\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.990746\n",
      "[LightGBM] [Info] Number of positive: 1551, number of negative: 2505\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1304\n",
      "[LightGBM] [Info] Number of data points in the train set: 4056, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382396 -> initscore=-0.479389\n",
      "[LightGBM] [Info] Start training from score -0.479389\n",
      "[1]\tvalid_0's auc: 0.991698\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.991999\n",
      "[3]\tvalid_0's auc: 0.993129\n",
      "[4]\tvalid_0's auc: 0.99303\n",
      "[5]\tvalid_0's auc: 0.993496\n",
      "[6]\tvalid_0's auc: 0.993649\n",
      "[7]\tvalid_0's auc: 0.994479\n",
      "[8]\tvalid_0's auc: 0.994421\n",
      "[9]\tvalid_0's auc: 0.994578\n",
      "[10]\tvalid_0's auc: 0.994657\n",
      "[11]\tvalid_0's auc: 0.994512\n",
      "[12]\tvalid_0's auc: 0.994661\n",
      "[13]\tvalid_0's auc: 0.994706\n",
      "[14]\tvalid_0's auc: 0.994659\n",
      "[15]\tvalid_0's auc: 0.99465\n",
      "[16]\tvalid_0's auc: 0.994875\n",
      "[17]\tvalid_0's auc: 0.994789\n",
      "[18]\tvalid_0's auc: 0.994801\n",
      "[19]\tvalid_0's auc: 0.99497\n",
      "[20]\tvalid_0's auc: 0.99502\n",
      "[21]\tvalid_0's auc: 0.995065\n",
      "[22]\tvalid_0's auc: 0.995107\n",
      "[23]\tvalid_0's auc: 0.99503\n",
      "[24]\tvalid_0's auc: 0.994981\n",
      "[25]\tvalid_0's auc: 0.994944\n",
      "[26]\tvalid_0's auc: 0.994813\n",
      "[27]\tvalid_0's auc: 0.994605\n",
      "[28]\tvalid_0's auc: 0.994681\n",
      "[29]\tvalid_0's auc: 0.994694\n",
      "[30]\tvalid_0's auc: 0.99497\n",
      "[31]\tvalid_0's auc: 0.994954\n",
      "[32]\tvalid_0's auc: 0.995012\n",
      "[33]\tvalid_0's auc: 0.994991\n",
      "[34]\tvalid_0's auc: 0.994832\n",
      "[35]\tvalid_0's auc: 0.994807\n",
      "[36]\tvalid_0's auc: 0.994756\n",
      "[37]\tvalid_0's auc: 0.99469\n",
      "[38]\tvalid_0's auc: 0.994789\n",
      "[39]\tvalid_0's auc: 0.994665\n",
      "[40]\tvalid_0's auc: 0.994553\n",
      "[41]\tvalid_0's auc: 0.994636\n",
      "[42]\tvalid_0's auc: 0.994661\n",
      "[43]\tvalid_0's auc: 0.994595\n",
      "[44]\tvalid_0's auc: 0.994541\n",
      "[45]\tvalid_0's auc: 0.994578\n",
      "[46]\tvalid_0's auc: 0.994611\n",
      "[47]\tvalid_0's auc: 0.994657\n",
      "[48]\tvalid_0's auc: 0.994541\n",
      "[49]\tvalid_0's auc: 0.994545\n",
      "[50]\tvalid_0's auc: 0.994442\n",
      "[51]\tvalid_0's auc: 0.994731\n",
      "[52]\tvalid_0's auc: 0.99459\n",
      "[53]\tvalid_0's auc: 0.994495\n",
      "[54]\tvalid_0's auc: 0.994504\n",
      "[55]\tvalid_0's auc: 0.994429\n",
      "[56]\tvalid_0's auc: 0.994442\n",
      "[57]\tvalid_0's auc: 0.994504\n",
      "[58]\tvalid_0's auc: 0.994491\n",
      "[59]\tvalid_0's auc: 0.9945\n",
      "[60]\tvalid_0's auc: 0.994421\n",
      "[61]\tvalid_0's auc: 0.994293\n",
      "[62]\tvalid_0's auc: 0.994326\n",
      "[63]\tvalid_0's auc: 0.994384\n",
      "[64]\tvalid_0's auc: 0.994248\n",
      "[65]\tvalid_0's auc: 0.99431\n",
      "[66]\tvalid_0's auc: 0.994334\n",
      "[67]\tvalid_0's auc: 0.994458\n",
      "[68]\tvalid_0's auc: 0.99445\n",
      "[69]\tvalid_0's auc: 0.994351\n",
      "[70]\tvalid_0's auc: 0.994392\n",
      "[71]\tvalid_0's auc: 0.994281\n",
      "[72]\tvalid_0's auc: 0.994264\n",
      "[73]\tvalid_0's auc: 0.994297\n",
      "[74]\tvalid_0's auc: 0.994367\n",
      "[75]\tvalid_0's auc: 0.994351\n",
      "[76]\tvalid_0's auc: 0.994343\n",
      "[77]\tvalid_0's auc: 0.994417\n",
      "[78]\tvalid_0's auc: 0.994405\n",
      "[79]\tvalid_0's auc: 0.994479\n",
      "[80]\tvalid_0's auc: 0.994442\n",
      "[81]\tvalid_0's auc: 0.994483\n",
      "[82]\tvalid_0's auc: 0.994479\n",
      "[83]\tvalid_0's auc: 0.994425\n",
      "[84]\tvalid_0's auc: 0.994462\n",
      "[85]\tvalid_0's auc: 0.994467\n",
      "[86]\tvalid_0's auc: 0.994405\n",
      "[87]\tvalid_0's auc: 0.994405\n",
      "[88]\tvalid_0's auc: 0.994483\n",
      "[89]\tvalid_0's auc: 0.994557\n",
      "[90]\tvalid_0's auc: 0.994669\n",
      "[91]\tvalid_0's auc: 0.994586\n",
      "[92]\tvalid_0's auc: 0.994636\n",
      "[93]\tvalid_0's auc: 0.994636\n",
      "[94]\tvalid_0's auc: 0.994669\n",
      "[95]\tvalid_0's auc: 0.994677\n",
      "[96]\tvalid_0's auc: 0.994529\n",
      "[97]\tvalid_0's auc: 0.994541\n",
      "[98]\tvalid_0's auc: 0.994566\n",
      "[99]\tvalid_0's auc: 0.994545\n",
      "[100]\tvalid_0's auc: 0.994574\n",
      "[101]\tvalid_0's auc: 0.994475\n",
      "[102]\tvalid_0's auc: 0.99445\n",
      "[103]\tvalid_0's auc: 0.9945\n",
      "[104]\tvalid_0's auc: 0.994462\n",
      "[105]\tvalid_0's auc: 0.994417\n",
      "[106]\tvalid_0's auc: 0.994434\n",
      "[107]\tvalid_0's auc: 0.994479\n",
      "[108]\tvalid_0's auc: 0.994475\n",
      "[109]\tvalid_0's auc: 0.994438\n",
      "[110]\tvalid_0's auc: 0.994446\n",
      "[111]\tvalid_0's auc: 0.994392\n",
      "[112]\tvalid_0's auc: 0.994363\n",
      "[113]\tvalid_0's auc: 0.994343\n",
      "[114]\tvalid_0's auc: 0.994421\n",
      "[115]\tvalid_0's auc: 0.994471\n",
      "[116]\tvalid_0's auc: 0.994487\n",
      "[117]\tvalid_0's auc: 0.994512\n",
      "[118]\tvalid_0's auc: 0.994487\n",
      "[119]\tvalid_0's auc: 0.994537\n",
      "[120]\tvalid_0's auc: 0.994491\n",
      "[121]\tvalid_0's auc: 0.994512\n",
      "[122]\tvalid_0's auc: 0.994491\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.995107\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "from sklearn.model_selection import KFold\n",
    "def select_by_lgb(train_data,train_label,test_data,random_state=2022,n_splits=5,metric='auc',num_round=10000,early_stopping_rounds=100):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    fold=0\n",
    "    result=[]\n",
    "    for train_idx, val_idx in kfold.split(train_data):\n",
    "        random_state+=1\n",
    "        train_x = train_data.loc[train_idx]\n",
    "        train_y = train_label.loc[train_idx]\n",
    "        test_x = train_data.loc[val_idx]\n",
    "        test_y = train_label.loc[val_idx]\n",
    "        clf=lightgbm\n",
    "        train_matrix=clf.Dataset(train_x,label=train_y)\n",
    "        test_matrix=clf.Dataset(test_x,label=test_y)\n",
    "        params={\n",
    "                'boosting_type': 'gbdt',  \n",
    "                'objective': 'binary',\n",
    "                'learning_rate': 0.1,\n",
    "                'metric': metric,\n",
    "                'seed': 2020,\n",
    "                'nthread':-1 }\n",
    "        model=clf.train(params,train_matrix,num_round,valid_sets=test_matrix,early_stopping_rounds=early_stopping_rounds)\n",
    "        pre_y=model.predict(test_data)\n",
    "        result.append(pre_y)\n",
    "        fold+=1\n",
    "    return result\n",
    "\n",
    "test_data=select_by_lgb(train,train_label,test)\n",
    "pre_y=pd.DataFrame(test_data).T\n",
    "pre_y['averge']=pre_y[[i for i in range(5)]].mean(axis=1)\n",
    "pre_y['label']=pre_y['averge'].apply(lambda x:1 if x>0.5 else 0)\n",
    "result=pd.read_csv('提交示例.csv')\n",
    "result['label']=pre_y['label']\n",
    "result.to_csv('lgb1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "LGBM-SK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9425808664290797"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "clf = LGBMClassifier(\n",
    "    boosting_type='gbdt',  # 提升树的类型 gbdt,dart,goss,rf\n",
    "    num_leaves=31,  #树的最大叶子数，对比xgboost一般为2^(max_depth)\n",
    "    max_depth=5,  #最大树的深度\n",
    "    learning_rate=0.05,  #学习率\n",
    "    n_estimators=200,  # 拟合的树的棵树，相当于训练轮数\n",
    "    subsample_for_bin=200000,\n",
    "    objective=None,\n",
    "    class_weight=None,\n",
    "    min_split_gain=0.0,  # 最小分割增益\n",
    "    min_child_weight=0.001,  # 分支结点的最小权重\n",
    "    min_child_samples=20,\n",
    "    subsample=1.0,  # 训练样本采样率 行\n",
    "    subsample_freq=0,  # 子样本频率\n",
    "    colsample_bytree=1.0,  # 训练特征采样率 列\n",
    "    colsample_bylevel=1.0,  # 训练特征采样率 列\n",
    "    colsample_bynode=1.0,  # 训练特征采样率 列\n",
    "    reg_alpha=0.0,  # L1正则化系数\n",
    "    reg_lambda=1,  # L2正则化系数\n",
    "    random_state=None,\n",
    "    n_jobs=-1,\n",
    "    silent=True,\n",
    ")\n",
    "clf.fit(train_x,train_y, eval_metric='auc')\n",
    "#设置验证集合 verbose=False不打印过程\n",
    "clf.fit(train_x,train_y)\n",
    "\n",
    "\n",
    "clf_hist_score = cross_val_score(clf,train,train_label,cv=10,scoring='f1').mean()\n",
    "clf_hist_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1453, number of negative: 2349\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305\n",
      "[LightGBM] [Info] Number of data points in the train set: 3802, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382167 -> initscore=-0.480359\n",
      "[LightGBM] [Info] Start training from score -0.480359\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "dtrain = lgb.Dataset(train_x, train_y)\n",
    "dtest = lgb.Dataset(val_x,val_y)\n",
    "\n",
    "max_depth = range(1,20,1)\n",
    "score = []\n",
    "for i in max_depth:\n",
    "    import lightgbm as lgb\n",
    "    params4 = {\n",
    "            'objective':'binary',\n",
    "            'eta':0.05,\n",
    "            'max_depth':i,\n",
    "            'num_leaves':31,\n",
    "            'lambda_l2':0.8,\n",
    "            'min_data_in_leaf':2,\n",
    "            'subsample':0.8,\n",
    "            'bagging_freq':1,\n",
    "            'feature_fraction':0.8,\n",
    "        #    'slient':True,\n",
    "            'seed': 1000\n",
    "            }\n",
    "\n",
    "    num_boost_round=100\n",
    "    lgb = lgb.train(params4,dtrain,num_boost_round)\n",
    "    lgb.predict(val_x)\n",
    "    Y_predict = pd.DataFrame(lgb.predict(val_x))\n",
    "    #因为竞赛需要提交最后的预测判断，而模型给出的预测结果是概率，因此我们认为概率>0.5的即该患者有糖尿病，概率<=0.5的没有糖尿病\n",
    "    Y_predict = Y_predict.loc[:,0].apply(lambda x:1 if x>0.5 else 0)\n",
    "    from sklearn.metrics import f1_score\n",
    "    score.append(round(f1_score(val_y,Y_predict),5))\n",
    "    #print(f'f1_score: {round(f1_score(val_y,Y_predict),5)}')\n",
    "\n",
    "plt.style.use('seaborn-dark')\n",
    "fig,ax = plt.subplots(1,figsize=(15,8))\n",
    "#ax.set_ylim(top=1,bottom=0.8)\n",
    "plt.plot(max_depth,score,color='g',label='max_drpth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 随机森林优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 基于网格的随机森林优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'max_depth': 11, 'max_features': 9, 'min_samples_leaf': 6, 'n_estimators': 150}\n",
      "best score: 0.9478654267303419\n",
      "train score: 0.9664243682935271\n",
      "test score: 0.9591623036649215\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "rfc=RandomForestClassifier(random_state=0\n",
    "                           #,n_estimators=151\n",
    "                           #,max_depth=11\n",
    "                           #,min_samples_leaf=5\n",
    "                           #,max_features=9\n",
    "                           )\n",
    "params={\n",
    "        'n_estimators':[*range(150,155,1)]\n",
    "        ,'max_depth':[*range(10,12,1)]\n",
    "        ,'min_samples_leaf':[4,5,6]\n",
    "        ,'max_features':[*range(1,20,1)]\n",
    "        #'max_samples':[*range(0.1,1,0.1)]\n",
    "        }\n",
    "\n",
    "rfc_cv=GridSearchCV(rfc,param_grid=params,refit=True,cv=5,n_jobs=-1,scoring=\"f1\").fit(train,train_label)\n",
    "\n",
    "print('best parameters:',rfc_cv.best_params_)\n",
    "print('best score:',rfc_cv.best_score_)       \n",
    "print('train score:',rfc_cv.score(train_x,train_y))         \n",
    "print('test score:',rfc_cv.score(val_x,val_y))              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 基于随机网格的随机森林优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: RandomForestClassifier(max_depth=11, max_features=9, min_samples_leaf=5,\n",
      "                       n_estimators=153, n_jobs=-1, random_state=1412,\n",
      "                       verbose=True)\n",
      "best score: 0.9474703631459815\n",
      "train score: 0.9688365650969529\n",
      "test score: 0.9644351464435146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 153 out of 153 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 153 out of 153 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 153 out of 153 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#创造参数空间 - 使用与网格搜索时完全一致的空间，以便于对比\n",
    "param_grid_simple = {#\"criterion\": [\"squared_error\",\"poisson\"]\n",
    "                    'n_estimators': [*range(140,160,2)],\n",
    "                    'max_depth': [*range(10,15,1)],\n",
    "                    'min_samples_leaf':[4,5,6],\n",
    "                    \"max_features\": [\"log2\",\"sqrt\",5,10,15,\"auto\"]\n",
    "                     #, \"min_impurity_decrease\": [*range(0,5,10)]\n",
    "                    }\n",
    "\n",
    "#建立回归器、交叉验证\n",
    "rfc = RandomForestClassifier(random_state=1412,verbose=True,n_jobs=-1)\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
    "rfc_rcv = RandomizedSearchCV(estimator=rfc\n",
    "                            ,param_distributions=params\n",
    "                            ,n_iter = 400 #子空间的大小是全域空间的一半左右\n",
    "                            ,scoring = \"f1\"\n",
    "                            ,verbose = True\n",
    "                            ,cv = cv\n",
    "                            ,random_state=1412\n",
    "                            ,n_jobs=-1\n",
    "                           ).fit(train,train_label)\n",
    "\n",
    "print('best parameters:',rfc_rcv.best_estimator_)\n",
    "print('best score:',rfc_rcv.best_score_)       \n",
    "print('train score:',rfc_rcv.score(train_x,train_y))         \n",
    "print('test score:',rfc_rcv.score(val_x,val_y))              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 基于hyperOPE贝叶斯优化随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:30<00:00,  1.01s/trial, best loss: 0.941756241192231] \n",
      "\n",
      " \n",
      " best params:  {'max_depth': 12.0, 'max_features': 14.0, 'n_estimators': 120.0} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials, partial\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "def hyperopt_objective(params):\n",
    "    \n",
    "    #定义评估器\n",
    "    #需要搜索的参数需要从输入的字典中索引出来\n",
    "    #不需要搜索的参数，可以是设置好的某个值\n",
    "    #在需要整数的参数前调整参数类型\n",
    "    reg = RandomForestClassifier(n_estimators = int(params[\"n_estimators\"])\n",
    "                                ,max_depth = int(params[\"max_depth\"])\n",
    "                                ,max_features = int(params[\"max_features\"])\n",
    "                                # ,min_impurity_decrease = params[\"min_impurity_decrease\"]\n",
    "                                ,random_state=1412\n",
    "                                ,verbose=False\n",
    "                                ,n_jobs=-1)\n",
    "    \n",
    "    #交叉验证结果，输出负根均方误差（-RMSE）\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
    "    validation_loss = cross_validate(reg,train_x,train_y\n",
    "                                     ,scoring=\"f1\"\n",
    "                                     ,cv=cv\n",
    "                                     ,verbose=False\n",
    "                                     ,n_jobs=-1\n",
    "                                     ,error_score='raise'\n",
    "                                    )\n",
    "    \n",
    "    #最终输出结果，由于只能取最小值，所以必须对（-RMSE）求绝对值\n",
    "    #以求解最小RMSE所对应的参数组合\n",
    "    return validation_loss[\"test_score\"].mean()\n",
    "\n",
    "# 样本空间\n",
    "param_grid_simple = {'n_estimators': hp.quniform(\"n_estimators\",120,180,10)\n",
    "                    , 'max_depth': hp.quniform(\"max_depth\",5,15,2)\n",
    "                    , \"max_features\": hp.quniform(\"max_features\",2,20,2)\n",
    "                    # , \"min_impurity_decrease\":hp.quniform(\"min_impurity_decrease\",0,5,1)\n",
    "                    }\n",
    "\n",
    "def param_hyperopt(max_evals=100):\n",
    "    \n",
    "    #保存迭代过程\n",
    "    trials = Trials()\n",
    "    \n",
    "    #设置提前停止\n",
    "    early_stop_fn = no_progress_loss(100)\n",
    "    \n",
    "    #定义代理模型\n",
    "    #algo = partial(tpe.suggest, n_startup_jobs=20, n_EI_candidates=50)\n",
    "    params_best = fmin(hyperopt_objective #目标函数\n",
    "                       , space = param_grid_simple #参数空间\n",
    "                       , algo = tpe.suggest #代理模型你要哪个呢？\n",
    "                       #, algo = algo\n",
    "                       , max_evals = max_evals #允许的迭代次数\n",
    "                       , verbose=True\n",
    "                       , trials = trials\n",
    "                       , early_stop_fn = early_stop_fn\n",
    "                      )\n",
    "    \n",
    "    #打印最优参数，fmin会自动打印最佳分数\n",
    "    print(\"\\n\",\"\\n\",\"best params: \", params_best,\n",
    "          \"\\n\")\n",
    "    return params_best, trials\n",
    "\n",
    "params_best, trials = param_hyperopt(30) #1%的空间大小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 基于optuna贝叶斯优化随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:34<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " best params:  {'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 189, 'max_depth': 14, 'max_features': 16} \n",
      " \n",
      " best score:  [0.9401562205453097] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'min_samples_leaf': 3,\n",
       "  'min_samples_split': 2,\n",
       "  'n_estimators': 189,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 16},\n",
       " [0.9401562205453097])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#目标函数\n",
    "def optuna_objective(trial):\n",
    "    \n",
    "    #定义参数空间\n",
    "    min_samples_leaf= trial.suggest_int(\"min_samples_leaf\",2,4,1)\n",
    "    min_samples_split= trial.suggest_int(\"min_samples_split\",2,5,1)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\",150,250,1) #整数型，(参数名称，下界，上界，步长)\n",
    "    max_depth = trial.suggest_int(\"max_depth\",8,16,1)\n",
    "    max_features = trial.suggest_int(\"max_features\",10,20,1)\n",
    "    #max_samples = trial.suggest_float(\"max_samples\",0,1)\n",
    "    #max_features = trial.suggest_categorical(\"max_features\",[\"log2\",\"sqrt\",\"auto\"]) #字符型\n",
    "    #min_impurity_decrease = trial.suggest_int(\"min_impurity_decrease\",0,5,1)\n",
    "    #min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\",0,5,log=False) #浮点型\n",
    "    \n",
    "    #定义评估器\n",
    "    #需要优化的参数由上述参数空间决定\n",
    "    #不需要优化的参数则直接填写具体值\n",
    "    rfc = RandomForestClassifier(n_estimators = n_estimators\n",
    "                                ,max_depth = max_depth\n",
    "                                ,max_features = max_features\n",
    "                                #,min_impurity_decrease = min_impurity_decrease\n",
    "                                ,min_samples_leaf=min_samples_leaf\n",
    "                                ,min_samples_split=min_samples_split\n",
    "                                #,max_samples=max_samples\n",
    "                                ,class_weight=\"balanced\"\n",
    "                                ,random_state=1412\n",
    "                                ,verbose=False\n",
    "                                ,n_jobs=-1\n",
    "                              )\n",
    "    \n",
    "    #交叉验证过程，输出负均方根误差(-RMSE)\n",
    "    #optuna同时支持最大化和最小化，因此如果输出-RMSE，则选择最大化\n",
    "    #如果选择输出RMSE，则选择最小化\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
    "    validation_loss = cross_validate(rfc,train,train_label\n",
    "                                     ,scoring=\"f1\"\n",
    "                                     ,cv=cv #交叉验证模式\n",
    "                                     ,verbose=False #是否打印进程\n",
    "                                     ,n_jobs=-1 #线程数\n",
    "                                     ,error_score='raise'\n",
    "                                    )\n",
    "    #最终输出RMSE\n",
    "    return np.mean(abs(validation_loss[\"test_score\"]))\n",
    "\n",
    "#优化函数\n",
    "def optimizer_optuna(n_trials, algo):\n",
    "    \n",
    "    #定义使用TPE或者GP\n",
    "    if algo == \"TPE\":\n",
    "        algo = optuna.samplers.TPESampler(n_startup_trials = 10, n_ei_candidates = 24)\n",
    "    elif algo == \"GP\":\n",
    "        from optuna.integration import SkoptSampler\n",
    "        import skopt\n",
    "        algo = SkoptSampler(skopt_kwargs={'base_estimator':'GP', #选择高斯过程\n",
    "                                          'n_initial_points':10, #初始观测点10个\n",
    "                                          'acq_func':'EI'} #选择的采集函数为EI，期望增量\n",
    "                           )\n",
    "    \n",
    "    #实际优化过程，首先实例化优化器\n",
    "    study = optuna.create_study(sampler = algo #要使用的具体算法\n",
    "                                , direction=\"minimize\" #优化的方向，可以填写minimize或maximize\n",
    "                               )\n",
    "    #开始优化，n_trials为允许的最大迭代次数\n",
    "    #由于参数空间已经在目标函数中定义好，因此不需要输入参数空间\n",
    "    study.optimize(optuna_objective #目标函数\n",
    "                   , n_trials=n_trials #最大迭代次数（包括最初的观测值的）\n",
    "                   , show_progress_bar=True #要不要展示进度条呀？\n",
    "                  )\n",
    "    \n",
    "    #可直接从优化好的对象study中调用优化的结果\n",
    "    #打印最佳参数与最佳损失值\n",
    "    print(\"\\n\",\"\\n\",\"best params: \", study.best_trial.params,\n",
    "          \"\\n\",\"\\n\",\"best score: \", study.best_trial.values,\n",
    "          \"\\n\")\n",
    "    \n",
    "    return study.best_trial.params, study.best_trial.values\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #关闭自动打印的info，只显示进度条\n",
    "#optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "optimizer_optuna(100,\"TPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9456317772274202"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RandomForestClassifier(max_depth=11\n",
    "                            ,min_samples_leaf=1\n",
    "                            ,min_samples_split=3\n",
    "                            ,n_estimators=160\n",
    "                          #  ,min_impurity_decrease = 0\n",
    "                            ,max_features=9\n",
    "                            ,random_state=2022\n",
    "                            )\n",
    "model = model.fit(train,train_label)\n",
    "score = cross_val_score(model,train,train_label,cv=5,scoring='f1').mean()\n",
    "score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 优化GBDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 基于optuna贝叶斯优化GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:36<00:00,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " best params:  {'learning_rate': 0.02, 'min_samples_leaf': 4, 'n_estimators': 140, 'max_depth': 17, 'max_features': 20, 'subsample': 1.0} \n",
      " \n",
      " best score:  [0.9383046452737499] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.02,\n",
       "  'min_samples_leaf': 4,\n",
       "  'n_estimators': 140,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 20,\n",
       "  'subsample': 1.0},\n",
       " [0.9383046452737499])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def optuna_objective(trial):\n",
    "    \n",
    "    #定义参数空间\n",
    "    learning_rate = trial.suggest_discrete_uniform(\"learning_rate\",0.01,0.1,0.01)\n",
    "    min_samples_split= trial.suggest_int(\"min_samples_leaf\",1,5,1)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\",140,160,1) #整数型，(参数名称，下界，上界，步长)\n",
    "    max_depth = trial.suggest_int(\"max_depth\",12,20,1)\n",
    "    max_features = trial.suggest_int(\"max_features\",16,20,1)\n",
    "    subsample = trial.suggest_discrete_uniform(\"subsample\",0.5,1,0.1)\n",
    "    #max_features = trial.suggest_categorical(\"max_features\",[\"log2\",\"sqrt\",\"auto\"]) #字符型\n",
    "    #min_impurity_decrease = trial.suggest_int(\"min_impurity_decrease\",0,5,1)\n",
    "    #min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\",0,5,log=False) #浮点型\n",
    "    \n",
    "    #定义评估器\n",
    "    #需要优化的参数由上述参数空间决定\n",
    "    #不需要优化的参数则直接填写具体值\n",
    "    GBDT = GradientBoostingClassifier(n_estimators = n_estimators\n",
    "                                      ,max_depth = max_depth\n",
    "                                      ,learning_rate=learning_rate\n",
    "                                      ,max_features = max_features\n",
    "                                      ,subsample =subsample \n",
    "                                      ,min_samples_leaf=min_samples_split\n",
    "                                    # ,min_impurity_decrease = min_impurity_decrease\n",
    "                                    # ,max_samples=0.8\n",
    "                                      ,random_state=1412\n",
    "                                      ,verbose=False\n",
    "                                    # ,n_jobs=-1\n",
    "                                    )\n",
    "    \n",
    "    #交叉验证过程，输出负均方根误差(-RMSE)\n",
    "    #optuna同时支持最大化和最小化，因此如果输出-RMSE，则选择最大化\n",
    "    #如果选择输出RMSE，则选择最小化\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
    "    validation_loss = cross_validate(GBDT,train,train_label\n",
    "                                     ,scoring=\"f1\"\n",
    "                                     ,cv=cv #交叉验证模式\n",
    "                                     ,verbose=False #是否打印进程\n",
    "                                     ,n_jobs=-1 #线程数\n",
    "                                     ,error_score='raise'\n",
    "                                    )\n",
    "    #最终输出RMSE\n",
    "    return np.mean(abs(validation_loss[\"test_score\"]))\n",
    "\n",
    "#优化函数\n",
    "def optimizer_optuna(n_trials, algo):\n",
    "    \n",
    "    #定义使用TPE或者GP\n",
    "    if algo == \"TPE\":\n",
    "        algo = optuna.samplers.TPESampler(n_startup_trials = 10, n_ei_candidates = 24)\n",
    "    elif algo == \"GP\":\n",
    "        from optuna.integration import SkoptSampler\n",
    "        import skopt\n",
    "        algo = SkoptSampler(skopt_kwargs={'base_estimator':'GP', #选择高斯过程\n",
    "                                          'n_initial_points':10, #初始观测点10个\n",
    "                                          'acq_func':'EI'} #选择的采集函数为EI，期望增量\n",
    "                           )\n",
    "    \n",
    "    #实际优化过程，首先实例化优化器\n",
    "    study = optuna.create_study(sampler = algo #要使用的具体算法\n",
    "                                , direction=\"minimize\" #优化的方向，可以填写minimize或maximize\n",
    "                               )\n",
    "    #开始优化，n_trials为允许的最大迭代次数\n",
    "    #由于参数空间已经在目标函数中定义好，因此不需要输入参数空间\n",
    "    study.optimize(optuna_objective #目标函数\n",
    "                   , n_trials=n_trials #最大迭代次数（包括最初的观测值的）\n",
    "                   , show_progress_bar=True #要不要展示进度条呀？\n",
    "                  )\n",
    "    \n",
    "    #可直接从优化好的对象study中调用优化的结果\n",
    "    #打印最佳参数与最佳损失值\n",
    "    print(\"\\n\",\"\\n\",\"best params: \", study.best_trial.params,\n",
    "          \"\\n\",\"\\n\",\"best score: \", study.best_trial.values,\n",
    "          \"\\n\")\n",
    "    \n",
    "    return study.best_trial.params, study.best_trial.values\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #关闭自动打印的info，只显示进度条\n",
    "#optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "optimizer_optuna(10,\"TPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 优化HGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 基于optuna贝叶斯优化HGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:30<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " best params:  {'max_iter': 500, 'learning_rate': 0.1} \n",
      " \n",
      " best score:  [0.9372678787743116] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_iter': 500, 'learning_rate': 0.1}, [0.9372678787743116])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def optuna_objective(trial):\n",
    "    \n",
    "    #定义参数空间\n",
    "    #loss = trial.suggest_categorical(\"loss\",[\"log_loss\", \"binary_crossentropy\", \"categorical_crossentropy\", \"auto\"])\n",
    "    max_iter = trial.suggest_int(\"max_iter\",300,500,50)\n",
    "    learning_rate = trial.suggest_discrete_uniform(\"learning_rate\",0.1,0.5,0.05)\n",
    "    #min_samples_leaf= trial.suggest_int(\"min_samples_leaf\",1,5,1)\n",
    "    #l2_regularization = trial.suggest_int(\"l2_regularization\",0,10,1)\n",
    "    #max_depth = trial.suggest_int(\"max_depth\",1,20,1)\n",
    "    #max_features = trial.suggest_int(\"max_features\",10,20,1)\n",
    "    #subsample = trial.suggest_int(\"subsample\",0.1,1,0.1)\n",
    "    #max_features = trial.suggest_categorical(\"max_features\",[\"log2\",\"sqrt\",\"auto\"]) #字符型\n",
    "    #min_impurity_decrease = trial.suggest_int(\"min_impurity_decrease\",0,5,1)\n",
    "    #min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\",0,5,log=False) #浮点型\n",
    "    \n",
    "    #定义评估器\n",
    "    #需要优化的参数由上述参数空间决定\n",
    "    #不需要优化的参数则直接填写具体值\n",
    "    hgb = HistGradientBoostingClassifier(max_iter = max_iter\n",
    "                                      #  ,max_depth = max_depth\n",
    "                                      #,loss = loss\n",
    "                                      #  ,min_samples_leaf = min_samples_leaf\n",
    "                                      #  ,l2_regularization=l2_regularization\n",
    "                                        ,learning_rate= learning_rate\n",
    "                                      #,max_features = max_features\n",
    "                                      # ,min_impurity_decrease = min_impurity_decrease\n",
    "                                      # ,max_samples=0.8\n",
    "                                        ,random_state=1412\n",
    "                                        ,verbose=False\n",
    "                                      # ,n_jobs=-1\n",
    "                                      )\n",
    "    \n",
    "    #交叉验证过程，输出负均方根误差(-RMSE)\n",
    "    #optuna同时支持最大化和最小化，因此如果输出-RMSE，则选择最大化\n",
    "    #如果选择输出RMSE，则选择最小化\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
    "    validation_loss = cross_validate(hgb,train,train_label\n",
    "                                     ,scoring=\"f1\"\n",
    "                                     ,cv=cv #交叉验证模式\n",
    "                                     ,verbose=False #是否打印进程\n",
    "                                     ,n_jobs=-1 #线程数\n",
    "                                     ,error_score='raise'\n",
    "                                    )\n",
    "    #最终输出RMSE\n",
    "    return np.mean(abs(validation_loss[\"test_score\"]))\n",
    "    \n",
    "#优化函数\n",
    "def optimizer_optuna(n_trials, algo):\n",
    "    \n",
    "    #定义使用TPE或者GP\n",
    "    if algo == \"TPE\":\n",
    "        algo = optuna.samplers.TPESampler(n_startup_trials = 10, n_ei_candidates = 24)\n",
    "    elif algo == \"GP\":\n",
    "        from optuna.integration import SkoptSampler\n",
    "        import skopt\n",
    "        algo = SkoptSampler(skopt_kwargs={'base_estimator':'GP', #选择高斯过程\n",
    "                                          'n_initial_points':10, #初始观测点10个\n",
    "                                          'acq_func':'EI'} #选择的采集函数为EI，期望增量\n",
    "                           )\n",
    "    \n",
    "    #实际优化过程，首先实例化优化器\n",
    "    study = optuna.create_study(sampler = algo #要使用的具体算法\n",
    "                                , direction=\"minimize\" #优化的方向，可以填写minimize或maximize\n",
    "                               )\n",
    "    #开始优化，n_trials为允许的最大迭代次数\n",
    "    #由于参数空间已经在目标函数中定义好，因此不需要输入参数空间\n",
    "    study.optimize(optuna_objective #目标函数\n",
    "                   , n_trials=n_trials #最大迭代次数（包括最初的观测值的）\n",
    "                   , show_progress_bar=True #要不要展示进度条呀？\n",
    "                  )\n",
    "    \n",
    "    #可直接从优化好的对象study中调用优化的结果\n",
    "    #打印最佳参数与最佳损失值\n",
    "    print(\"\\n\",\"\\n\",\"best params: \", study.best_trial.params,\n",
    "          \"\\n\",\"\\n\",\"best score: \", study.best_trial.values,\n",
    "          \"\\n\")\n",
    "    \n",
    "    return study.best_trial.params, study.best_trial.values\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #关闭自动打印的info，只显示进度条\n",
    "#optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "optimizer_optuna(200,\"TPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 优化XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 基于随机网格搜索优化XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "[23:17:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_features\", \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "best parameters: XGBClassifier(base_score=0.5, booster='dart', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=3, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.05, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=15, max_features='sqrt', max_leaves=0,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=190, n_jobs=-1, num_parallel_tree=1,\n",
      "              predictor='auto', random_state=1412, reg_alpha=0, ...)\n",
      "best score: 0.9475096590601051\n",
      "train score: 0.9779462439696762\n",
      "test score: 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#创造参数空间 - 使用与网格搜索时完全一致的空间，以便于对比\n",
    "params = {\n",
    "        'n_estimators': [*range(100,200,10)]\n",
    "        , 'max_depth': [*range(5,20,5)]\n",
    "        , \"max_features\": [\"log2\",\"sqrt\",5,10,15,\"auto\"]\n",
    "        ,\"gamma\":[1,3,5,7,9]\n",
    "        ,\"learning_rate\":[0.01,0.05,0.1]\n",
    "        #,\"booster\":\"dart\"\n",
    "        #,\"max_depth = max_depth\n",
    "        #,\"max_features = max_features\n",
    "        #,\"colsample_bytree=colsample_bytree\n",
    "        #,\"colsample_bynode=colsample_bynode\n",
    "        #,\"min_child_weight=min_child_weight\n",
    "        #,\"reg_lambda=reg_lambda\n",
    "        }\n",
    "\n",
    "#建立回归器、交叉验证\n",
    "rfc = XGBClassifier(booster=\"dart\",random_state=1412,verbose=True,n_jobs=-1)\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
    "xgb_rcv = RandomizedSearchCV(estimator=rfc\n",
    "                            ,param_distributions=params\n",
    "                            ,n_iter = 200 #子空间的大小是全域空间的一半左右\n",
    "                            ,scoring = \"f1\"\n",
    "                            ,verbose = True\n",
    "                            ,cv = cv\n",
    "                            ,random_state=1412\n",
    "                            ,n_jobs=-1\n",
    "                           ).fit(train,train_label)\n",
    "\n",
    "print('best parameters:',xgb_rcv.best_estimator_)\n",
    "print('best score:',xgb_rcv.best_score_)       \n",
    "print('train score:',xgb_rcv.score(train_x,train_y))         \n",
    "print('test score:',xgb_rcv.score(val_x,val_y))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 基于hyperOPT贝叶斯优化XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#导入优化算法\n",
    "import hyperopt\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import hp, fmin, tpe, Trials, partial\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "#data_xgb = xgb.DMatrix(train_x,train_y)\n",
    "def hyperopt_objective(params):\n",
    "    paramsforxgb = {\"eta\":params[\"eta\"]\n",
    "                    ,\"booster\":params[\"booster\"]\n",
    "                    ,\"colsample_bytree\":params[\"colsample_bytree\"]\n",
    "                    ,\"colsample_bynode\":params[\"colsample_bynode\"]\n",
    "                    #,\"gamma\":params[\"gamma\"]\n",
    "                    ,\"lambda\":params[\"lambda\"]\n",
    "                    ,\"min_child_weight\":params[\"min_child_weight\"]\n",
    "                    ,\"max_depth\":int(params[\"max_depth\"])\n",
    "                    ,\"subsample\":params[\"subsample\"]\n",
    "                    ,\"objective\":params[\"objective\"]\n",
    "                    ,\"rate_drop\":params[\"rate_drop\"]\n",
    "                    ,\"nthread\":14\n",
    "                    ,\"verbosity\":0\n",
    "                    ,\"seed\":1412}\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "                        eta = int(params[\"eta\"]),\n",
    "                        booster=int(params[\"booster\"]),\n",
    "                        colsample_bytree=int(params[\"colsample_bytree\"]),\n",
    "                        colsample_bynode=int(params[\"colsample_bynode\"]),\n",
    "                        #gamma\":params[\"gamma\"],\n",
    "                        #lambda=int(params[\"lambda\"]),\n",
    "                        #min_child_weight=int(params[\"min_child_weight\"]),\n",
    "                        #max_depth=int(params[\"max_depth\"]),\n",
    "                        #subsample=int(params[\"subsample\"]),\n",
    "                        #objective=int(params[\"objective\"]),\n",
    "                        #rate_drop=int(params[\"rate_drop\"])\n",
    "                        )\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
    "    validation_loss = cross_validate(xgb,train,train_label\n",
    "                                     ,scoring=\"f1\"\n",
    "                                     ,cv=cv #交叉验证模式\n",
    "                                     ,verbose=False #是否打印进程\n",
    "                                     ,n_jobs=-1 #线程数\n",
    "                                     ,error_score='raise'\n",
    "                                     )\n",
    "    #最终输出RMSE\n",
    "    return np.mean(abs(validation_loss[\"test_score\"]))\n",
    "\n",
    "param_grid_simple = {'num_boost_round': hp.quniform(\"num_boost_round\",50,200,10)\n",
    "                     ,\"eta\": hp.quniform(\"eta\",0.05,2.05,0.05)\n",
    "                     ,\"booster\":hp.choice(\"booster\",[\"gbtree\",\"dart\"])\n",
    "                     ,\"colsample_bytree\":hp.quniform(\"colsample_bytree\",0.3,1,0.1)\n",
    "                     ,\"colsample_bynode\":hp.quniform(\"colsample_bynode\",0.1,1,0.1)\n",
    "                    # ,\"gamma\":hp.quniform(\"gamma\",1e6,1e7,1e6)\n",
    "                     ,\"lambda\":hp.quniform(\"lambda\",0,3,0.2)\n",
    "                     ,\"min_child_weight\":hp.quniform(\"min_child_weight\",0,50,2)\n",
    "                     ,\"max_depth\":hp.choice(\"max_depth\",[*range(2,30,2)])\n",
    "                     ,\"subsample\":hp.quniform(\"subsample\",0.1,1,0.1)\n",
    "                     ,\"objective\":hp.choice(\"objective\",[\"binary:logistic\",\"binary:hinge\"])\n",
    "                     ,\"rate_drop\":hp.quniform(\"rate_drop\",0.1,1,0.1)\n",
    "                    }\n",
    "\n",
    "def param_hyperopt(max_evals=100):\n",
    "    \n",
    "    #保存迭代过程\n",
    "    trials = Trials()\n",
    "    \n",
    "    #设置提前停止\n",
    "    early_stop_fn = no_progress_loss(30)\n",
    "    \n",
    "    #定义代理模型\n",
    "    params_best = fmin(hyperopt_objective\n",
    "                       , space = param_grid_simple\n",
    "                       , algo = tpe.suggest\n",
    "                       , max_evals = max_evals\n",
    "                       , verbose=True\n",
    "                       , trials = trials\n",
    "                       , early_stop_fn = early_stop_fn\n",
    "                      )\n",
    "    \n",
    "    #打印最优参数，fmin会自动打印最佳分数\n",
    "    print(\"\\n\",\"\\n\",\"best params: \", params_best,\n",
    "          \"\\n\")\n",
    "    return params_best, trials\n",
    "\n",
    "params_best, trials = param_hyperopt(100) #由于参数空间巨大，给与100次迭代的空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 基于optuna贝叶斯优化XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [02:01<3:20:27, 121.49s/it]"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def optuna_objective(trial):\n",
    "    \n",
    "    #定义参数空间\n",
    "    gamma= trial.suggest_int(\"gamma\",3,5,1)\n",
    "    #learning_rate = trial.suggest_float(\"learning_rate\",0.1,0.5)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\",210,230,5) #整数型，(参数名称，下界，上界，步长)\n",
    "    #booster = trial.suggest_categorical(\"booster\",[\"gbtree\",\"dart\"])\n",
    "    #reg_lambda = trial.suggest_float(\"reg_lambda\",0.3,0.5)\n",
    "    #colsample_bytree = trial.suggest_float(\"colsample_bytree\",0.3,1)\n",
    "    #colsample_bynode=trial.suggest_float(\"colsample_bynode\",0.1,1)\n",
    "    #min_child_weight=trial.suggest_int(\"min_child_weight\",0,50,2)\n",
    "    #max_depth = trial.suggest_int(\"max_depth\",6,16,2)\n",
    "    #max_features = trial.suggest_int(\"max_features\",0,20,4)\n",
    "    #subsample = trial.suggest_float(\"subsample\",0.1,1)\n",
    "    #max_features = trial.suggest_categorical(\"max_features\",[\"log2\",\"sqrt\",\"auto\"]) #字符型\n",
    "    #min_impurity_decrease = trial.suggest_int(\"min_impurity_decrease\",0,5,1)\n",
    "    #min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\",0,5,log=False) #浮点型\n",
    "    \n",
    "    #定义评估器\n",
    "    xgb = XGBClassifier(\n",
    "                        gamma=gamma,\n",
    "                        n_estimators = n_estimators,\n",
    "                        #learning_rate=learning_rate,\n",
    "                        booster=\"dart\",\n",
    "                        #max_depth = max_depth,\n",
    "                        #max_features = max_features,\n",
    "                        #colsample_bytree=colsample_bytree,\n",
    "                        #colsample_bynode=colsample_bynode,\n",
    "                        #min_child_weight=min_child_weight,\n",
    "                        #reg_lambda=reg_lambda,\n",
    "                        #subsample=subsample,\n",
    "                        random_state=1412,\n",
    "                        verbose=False,\n",
    "                        tree_method='gpu_hist', \n",
    "                        gpu_id=0,\n",
    "                        n_jobs=-1\n",
    "                      )\n",
    "    \n",
    "    #交叉验证过程，输出验证分数\n",
    "    #optuna同时支持最大化和最小化，因此如果输出-RMSE，则选择最大化\n",
    "    #如果选择输出RMSE，则选择最小化\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
    "    validation_loss = cross_validate(xgb,train,train_label\n",
    "                                     ,scoring=\"f1\"\n",
    "                                     ,cv=cv #交叉验证模式\n",
    "                                     ,verbose=False #是否打印进程\n",
    "                                     ,n_jobs=-1 #线程数\n",
    "                                     ,error_score='raise'\n",
    "                                    )\n",
    "    #最终输出RMSE\n",
    "    return np.mean(abs(validation_loss[\"test_score\"]))\n",
    "    \n",
    "#优化函数\n",
    "def optimizer_optuna(n_trials, algo):\n",
    "    \n",
    "    #定义使用TPE或者GP\n",
    "    if algo == \"TPE\":\n",
    "        algo = optuna.samplers.TPESampler(n_startup_trials = 10, n_ei_candidates = 24)\n",
    "    elif algo == \"GP\":\n",
    "        from optuna.integration import SkoptSampler\n",
    "        import skopt\n",
    "        algo = SkoptSampler(skopt_kwargs={'base_estimator':'GP', #选择高斯过程\n",
    "                                          'n_initial_points':10, #初始观测点10个\n",
    "                                          'acq_func':'EI'} #选择的采集函数为EI，期望增量\n",
    "                           )\n",
    "    \n",
    "    #实际优化过程，首先实例化优化器\n",
    "    study = optuna.create_study(sampler = algo #要使用的具体算法\n",
    "                                , direction=\"minimize\" #优化的方向，可以填写minimize或maximize\n",
    "                               )\n",
    "    #开始优化，n_trials为允许的最大迭代次数\n",
    "    #由于参数空间已经在目标函数中定义好，因此不需要输入参数空间\n",
    "    study.optimize(optuna_objective #目标函数\n",
    "                   , n_trials=n_trials #最大迭代次数（包括最初的观测值的）\n",
    "                   , show_progress_bar=True #要不要展示进度条呀？\n",
    "                  )\n",
    "    \n",
    "    #可直接从优化好的对象study中调用优化的结果\n",
    "    #打印最佳参数与最佳损失值\n",
    "    print(\"\\n\",\"\\n\",\"best params: \", study.best_trial.params,\n",
    "          \"\\n\",\"\\n\",\"best score: \", study.best_trial.values,\n",
    "          \"\\n\")\n",
    "    \n",
    "    return study.best_trial.params, study.best_trial.values\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #关闭自动打印的info，只显示进度条\n",
    "#optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "optimizer_optuna(100,\"TPE\")\n",
    "\n",
    "#best params:  {'gamma': 3, 'n_estimators': 250} \n",
    "#best score:  [0.9448901797866125] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 优化LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 基于optuna贝叶斯优化LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:16<00:00,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " best params:  {'n_estimators': 300} \n",
      " \n",
      " best score:  [0.9428580997770084] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def optuna_objective(trial):\n",
    "    \n",
    "    #定义参数空间\n",
    "    #gama= trial.suggest_discrete_uniform(\"gama\",0,10,1)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\",100,300,50) #整数型，(参数名称，下界，上界，步长)\n",
    "    #learning_rate = trial.suggest_discrete_uniform(\"learning_rate\",0.1,0.5,0.1)\n",
    "    #max_depth = trial.suggest_int(\"max_depth\",1,15,1)\n",
    "    #max_features = trial.suggest_int(\"max_features\",1,20,1)\n",
    "    #num_leaves = trial.suggest_int(\"max_leaves\",10,100,10)\n",
    "    #max_bin = trial.suggest_int(\"max_bin\",20,250,10)\n",
    "    #max_features = trial.suggest_categorical(\"max_features\",[\"log2\",\"sqrt\",\"auto\"]) #字符型\n",
    "    #max_features = trial.suggest_categorical(\"max_features\",[\"log2\",\"sqrt\",\"auto\"]) #字符型\n",
    "    #min_impurity_decrease = trial.suggest_int(\"min_impurity_decrease\",0,5,1)\n",
    "    #min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\",0,5,log=False) #浮点型\n",
    "    \n",
    "    #定义评估器\n",
    "    #需要优化的参数由上述参数空间决定\n",
    "    #不需要优化的参数则直接填写具体值\n",
    "    lgb = LGBMClassifier(n_estimators = n_estimators,\n",
    "                        #learning_rate=learning_rate,\n",
    "                        #max_depth = max_depth,\n",
    "                        #num_leaves=num_leaves,\n",
    "                        #gama=gama,\n",
    "                        #max_features = max_features,\n",
    "                        #max_bin=max_bin,\n",
    "                        #min_impurity_decrease = min_impurity_decrease,\n",
    "                        #max_samples=0.8,\n",
    "                        random_state=2022,\n",
    "                        verbose=0,\n",
    "                        n_jobs=-1\n",
    "                        )\n",
    "    \n",
    "    #交叉验证过程，输出负均方根误差(-RMSE)\n",
    "    #optuna同时支持最大化和最小化，因此如果输出-RMSE，则选择最大化\n",
    "    #如果选择输出RMSE，则选择最小化\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
    "    validation_loss = cross_validate(lgb,train,train_label\n",
    "                                     ,scoring=\"f1\"\n",
    "                                     ,cv=cv #交叉验证模式\n",
    "                                     ,verbose=False #是否打印进程\n",
    "                                     ,n_jobs=-1 #线程数\n",
    "                                     ,error_score='raise'\n",
    "                                    )\n",
    "    #最终输出RMSE\n",
    "    return np.mean(abs(validation_loss[\"test_score\"]))\n",
    "    \n",
    "#优化函数\n",
    "def optimizer_optuna(n_trials, algo):\n",
    "    \n",
    "    #定义使用TPE或者GP\n",
    "    if algo == \"TPE\":\n",
    "        algo = optuna.samplers.TPESampler(n_startup_trials = 10, n_ei_candidates = 24)\n",
    "    elif algo == \"GP\":\n",
    "        from optuna.integration import SkoptSampler\n",
    "        import skopt\n",
    "        algo = SkoptSampler(skopt_kwargs={'base_estimator':'GP', #选择高斯过程\n",
    "                                          'n_initial_points':10, #初始观测点10个\n",
    "                                          'acq_func':'EI'} #选择的采集函数为EI，期望增量\n",
    "                           )\n",
    "    \n",
    "    #实际优化过程，首先实例化优化器\n",
    "    study = optuna.create_study(sampler = algo #要使用的具体算法\n",
    "                                , direction=\"minimize\" #优化的方向，可以填写minimize或maximize\n",
    "                               )\n",
    "    #开始优化，n_trials为允许的最大迭代次数\n",
    "    #由于参数空间已经在目标函数中定义好，因此不需要输入参数空间\n",
    "    study.optimize(optuna_objective #目标函数\n",
    "                   , n_trials=n_trials #最大迭代次数（包括最初的观测值的）\n",
    "                   , show_progress_bar=True #要不要展示进度条呀？\n",
    "                  )\n",
    "    \n",
    "    #可直接从优化好的对象study中调用优化的结果\n",
    "    #打印最佳参数与最佳损失值\n",
    "    print(\"\\n\",\"\\n\",\"best params: \", study.best_trial.params,\n",
    "          \"\\n\",\"\\n\",\"best score: \", study.best_trial.values,\n",
    "          \"\\n\")\n",
    "    \n",
    "    return study.best_trial.params, study.best_trial.values\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #关闭自动打印的info，只显示进度条\n",
    "#optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "best_params,best_score = optimizer_optuna(200,\"TPE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# voting模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1平均值：0.9442\n",
      "f1标准差：0.0125\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 需要以元组的列表方式来构建estimators\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=11, \n",
    "                             min_samples_leaf=5, \n",
    "                             n_estimators=151,\n",
    "                             max_features=9,\n",
    "                             random_state=2022\n",
    "                             )\n",
    "gbc = GradientBoostingClassifier(n_estimators=131\n",
    "                                ,max_depth=18\n",
    "                                ,max_features=19\n",
    "                                ,learning_rate=0.01\n",
    "                                ,random_state=2022\n",
    "                                )\n",
    "hgb = HistGradientBoostingClassifier(max_iter =84                  \n",
    "                                    ,learning_rate=0.01\n",
    "                                    ,max_depth=33\n",
    "                                    ,min_samples_leaf=2\n",
    "                                    ,random_state=2022\n",
    "                                    ,l2_regularization=0\n",
    "                                    )\n",
    "\n",
    "lgbm = LGBMClassifier(gama=0\n",
    "                      #,n_estimators=181\n",
    "                      #,learning_rate=0.01\n",
    "                      ,random_state=2022\n",
    "                      ,n_estimators=119\n",
    "                      ,booster=\"dart\"\n",
    "                      ,learning_rate=0.06\n",
    "                      ,max_depth=6\n",
    "                      ,max_feature=13\n",
    "                      ,objective='binary'\n",
    "                      ,subsample=0.8\n",
    "                      ,reg_lambda=1\n",
    "                      ,min_impurity_decrease = 4\n",
    "                    )\n",
    "xgb = XGBClassifier(gama=9\n",
    "                    ,n_estimators=181\n",
    "                    ,learning_rate=0.01\n",
    "                    ,random_state=2022\n",
    "                    ,max_depth=6\n",
    "                    ,max_feature=18\n",
    "                    ,objective='binary:logistic'\n",
    "                    ,subsample=0.8\n",
    "                    ,reg_lambda=1\n",
    "                    ,min_impurity_decrease = 3\n",
    "                    )\n",
    "\n",
    "estimators = [(\"RFC\",rfc),\n",
    "              (\"GBC\",gbc),\n",
    "              (\"HGB\",hgb),\n",
    "              (\"LGBM\",lgbm),\n",
    "              (\"XGB\",xgb)]\n",
    "              \n",
    "mix = VotingClassifier(estimators,verbose=True) # vervose监控过程\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
    "mix_result = cross_validate(mix,train_x,train_y\n",
    "                                     ,scoring=\"f1\"\n",
    "                                     ,cv=cv #交叉验证模式\n",
    "                                     ,verbose=False #是否打印进程\n",
    "                                     ,n_jobs=-1 #线程数\n",
    "                                     ,error_score='raise'\n",
    "                                    )\n",
    "\n",
    "#mix_result = cross_val_score(mix,train,train_label,cv=5,n_jobs=-1,scoring=\"f1\")\n",
    "print(f'f1平均值：{round(mix_result[\"test_score\"].mean(),4)}')\n",
    "print(f'f1标准差：{round(mix_result[\"test_score\"].std(),4)}')\n",
    "\n",
    "plt.style.use('seaborn-dark')\n",
    "fig,ax = plt.subplots(1,figsize=(8,4))\n",
    "ax.set_ylim(top=1,bottom=0.8)\n",
    "plt.plot(range(1,6),mix_result[\"test_score\"],color='red',label='voting_result')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1平均值是：0.9436\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 需要以元组的列表方式来构建estimators\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "hgb = HistGradientBoostingClassifier()\n",
    "lgbm = LGBMClassifier()\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "estimators = [(\"RFC\",rfc),\n",
    "              (\"GBC\",gbc),\n",
    "              (\"HGB\",hgb),\n",
    "              (\"LGBM\",lgbm),\n",
    "              (\"XGB\",xgb)]\n",
    "              \n",
    "mix = VotingClassifier(estimators,verbose=True) # vervose监控过程\n",
    "mix_result = cross_val_score(mix,train,train_label,cv=5,n_jobs=-1,scoring=\"f1\")\n",
    "print(f'f1平均值是：{round(mix_result.mean(),4)}')\n",
    "\n",
    "plt.style.use('seaborn-dark')\n",
    "fig,ax = plt.subplots(1,figsize=(8,4))\n",
    "ax.set_ylim(top=1,bottom=0.8)\n",
    "plt.plot(range(1,6),mix_result,color='red',label='voting_result')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ...................... (1 of 2) Processing RFC, total=   1.2s\n",
      "[16:36:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gama\", \"max_feature\", \"min_impurity_decrease\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[Voting] ...................... (2 of 2) Processing XGB, total=   0.3s\n"
     ]
    }
   ],
   "source": [
    "mix = mix.fit(train,train_label)\n",
    "pre_y=mix.predict(test)\n",
    "result=pd.read_csv('提交示例.csv')\n",
    "result['label']=pre_y\n",
    "result.to_csv('voting.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 结果提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9465158302817731"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RandomForestClassifier(max_depth=11,\n",
    "                             min_samples_leaf=5,\n",
    "                             n_estimators=151,\n",
    "                             max_features=9,\n",
    "                             random_state=2022\n",
    "                             )\n",
    "model = model.fit(train,train_label)\n",
    "score = cross_val_score(model,train,train_label,cv=5,scoring='f1').mean()\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.975013150973172, 0.9550473186119873)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x,train_y)\n",
    "model.score(train_x,train_y),model.score(val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pre_y=model.predict(test)\n",
    "result=pd.read_csv('提交示例.csv')\n",
    "result['label']=pre_y\n",
    "result.to_csv('rfc.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#导入\n",
    "from hpsklearn import HyperoptEstimator\n",
    "\n",
    "#实例化\n",
    "estim = HyperoptEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#训练\n",
    "estim.fit(train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prediction = estim.predict(val_x)\n",
    "score = estim.score(val_y,val_x)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#直接返回sklearn中存在的，选择出的最好模型\n",
    "model = estim.best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_validate\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DecisionTreeClassifier' from 'sklearn.ensemble' (C:\\Users\\mjl\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VotingClassifier\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier,GradientBoostingClassifier,HistGradientBoostingClassifier,DecisionTreeClassifier\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DecisionTreeClassifier' from 'sklearn.ensemble' (C:\\Users\\mjl\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,HistGradientBoostingClassifier,DecisionTreeClassifier\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "825850a1542703e8330eb48918fb3db9db9b2154f7cb48e5f7ab1215ef3a88b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
